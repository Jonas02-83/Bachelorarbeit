
\chapter{Grundlagen} \index{Grundlagen}

TODO!!!!!!!!!

\section{LLM Tools} \index{LLM Tools} \label{LLM Tools}

Unter LLM-Tools versteht man Sprachmodelle, die auf einem Large Language Model (LLM) basieren. Ein LLM ist ein 
Deep-Learning-Algorithmus, der mit sehr großen Datensätzen trainiert wird. Diese Modelle finden häufig Anwendung im 
Bereich des Natural Language Processing (NLP), wo sie verwendet werden, um Abfragen in natürlicher Sprache zu beantworten 
oder Ergebnisse zu liefern. LLMs können neue Inhalte verstehen, zusammenfassen, generieren und vorhersagen. Durch das Training 
sammeln LLMs Milliarden von Parametern, bei denen es sich um Variablen handelt, die im Modell angepasst werden, um neue 
Inhalte abzuleiten.\\
LLMs basieren auf einem Transformer-Modell, das Eingaben in Token umwandelt und dann gleichzeitig mathematische 
Gleichungen ausführt, um Beziehungen zwischen den Token zu ermitteln. Dadurch kann der Computer Muster erkennen, 
die auch ein Mensch wahrnehmen würde, wenn ihm die gleiche Frage gestellt wird. Zudem verwenden Transformer-Modelle 
Selbstaufmerksamkeitsmechanismen, die es dem Modell ermöglichen, schneller zu lernen als herkömmliche Modelle. 
Dadurch kann das Transformer-Modell verschiedene Teile der Sequenz oder den gesamten Kontext eines Satzes berücksichtigen, 
um Vorhersagen zu generieren.

Grundsätzlich bestehen LLMs aus vier neuronalen Netzwerkschichten: der wiederkehrenden Ebene, der Einbettungsebene, 
der Feedforward-Ebene und der Aufmerksamkeitsebene. Diese Schichten arbeiten zusammen, um den Eingabetext zu verarbeiten 
und Ausgabeinhalte zu generieren.\\
Die wiederkehrende Ebene dient dazu, die Wörter des Eingabetextes der Reihe nach zu interpretieren und die Beziehungen 
zwischen den Wörtern in einem Satz zu erfassen. Die Einbettungsebene erfasst die semantische und syntaktische Bedeutung 
der Eingabe, sodass das Modell den Kontext verstehen kann. Die Feedforward-Schicht besteht aus mehreren vollständig 
verbundenen Schichten, die die Eingabeeinbettungen transformieren. Dadurch ermöglichen diese Schichten dem Modell, 
Abstraktionen auf höherer Ebene zu verstehen und somit die Absicht des Benutzers mit der Texteingabe zu erfassen. Die 
Aufmerksamkeitsebene ermöglicht es dem Sprachmodell, sich auf einzelne Teile des Eingabetextes zu konzentrieren, die für 
die Aufgabe relevant sind, und dadurch die genausten Ausgaben zu generieren.

Damit ein großes Sprachmodell Texteingaben empfangen und eine Ausgabevorhersage generieren kann, muss es zunächst 
allgemein geschult und anschließend feinabgestimmt werden, um spezifische Aufgaben ausführen zu können. Für die 
Schulung werden riesige Datenmengen im Petabyte-Bereich benötigt. Das Training verläuft mehrstufig und beginnt in 
der Regel mit einem unbeaufsichtigten Lernansatz, bei dem das Modell mit unstrukturierten und unbeschrifteten Daten 
trainiert wird, da diese in größeren Mengen verfügbar sind. In dieser Phase leitet das Modell Beziehungen zwischen 
verschiedenen Wörtern und Konzepten ab.\\
Anschließend erfolgt die Schulung und Feinabstimmung durch eine Form des selbstüberwachten Lernens. Dabei wird eine 
Datenkennzeichnung durchgeführt, durch die das Modell verschiedene Konzepte besser und genauer identifizieren kann. 
Im nächsten Schritt durchläuft das LLM den transformatorischen neuronalen Netzwerkprozess im Rahmen des Deep Learning. 
Die Transformer-Modellarchitektur ermöglicht es dem LLM, mittels eines Selbstaufmerksamkeitsmechanismus Beziehungen 
und Verbindungen zwischen Wörtern und Konzepten zu erkennen, indem bestimmten Elementen (Token) Bewertungen zugewiesen 
werden, um die Beziehungen festzulegen.

Entscheidend über die Leistungsfähigkeit und die Qualität des Sprachmodells sind die Datensätze, welche zum trainieren
benutzt werden. Im folgenden wird auf die drei unterschiedliche LLM-Tools eingeganden, welche in dieser Arbeit näher 
untersucht werden\cite{GrundlagenLLM}. 

\subsection{ChatGPT} \index{ChatGPT} \label{ChatGPT}


ChatGPT wurde von OpenAI am 30. November 2022 veröffentlicht und entwickelte sich aufgrund seiner fortschrittlichen 
generativen KI-Fähigkeiten rasch zu einer internationalen Sensation. Wenn man ChatGPT fragt, ob es einen Infotext 
zu sich selbst erstellen kann, erhält man die Antwort in Abbildung \ref{InfotextChatGPT}

\begin{figure} 
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
    \textbf{Prompt: Erstell mir einen Infotext über dich für meine Bachelorarbeit}\\ 

    ChatGPT ist ein fortschrittlicher KI-gestützter Sprachassistent, der auf der GPT-4-Architektur von OpenAI basiert. 
    Entwickelt im Rahmen der Forschung und Entwicklung im Bereich Künstliche Intelligenz, ist ChatGPT in der Lage, 
    natürliche Sprache zu verstehen und darauf zu antworten. Dies macht ihn zu einem vielseitigen Werkzeug für eine 
    Vielzahl von Anwendungen, von der Beantwortung alltäglicher Fragen bis hin zur Unterstützung bei komplexeren 
    Aufgaben wie dem Schreiben von Texten, der Generierung von Ideen und der Bereitstellung von Informationen.\\
    
    Die GPT-4-Architektur, auf der ChatGPT basiert, verwendet tiefes maschinelles Lernen, um menschliche Sprache zu 
    verarbeiten und zu erzeugen. Durch die Analyse großer Mengen an Textdaten kann das Modell Muster und Zusammenhänge 
    erkennen, die es ihm ermöglichen, kontextuell relevante und kohärente Antworten zu geben. Diese Fähigkeiten machen 
    ChatGPT zu einem nützlichen Instrument in Bereichen wie Bildung, Forschung, Kundenservice und mehr.\\
    
    Ein weiterer bemerkenswerter Aspekt von ChatGPT ist seine Fähigkeit, sich an eine Vielzahl von Themen anzupassen 
    und Informationen auf klare und präzise Weise zu vermitteln. Dies wird durch kontinuierliches Training und 
    Verbesserung des Modells erreicht, wobei sowohl technische Fortschritte als auch Nutzerfeedback berücksichtigt 
    werden.\\
    
    Zusammengefasst ist ChatGPT ein leistungsstarker und vielseitiger KI-Assistent, der durch seine fortschrittliche 
    Technologie und seine breite Anwendbarkeit einen wertvollen Beitrag in vielen Bereichen leistet.\\
    \vfill
    \end{tcolorbox}
    \caption{Quelle: ChatGPT}
    \label{InfotextChatGPT}
\end{figure}

Die Beta-Version der Plattform war zunächst kostenlos verfügbar, und OpenAI bot den Nutzern weiterhin eine kostenlose 
Basisversion an. Im Februar 2023 führte OpenAI ein kostenpflichtiges Abonnement ein, das unbegrenzten Zugriff auf ChatGPT 
sowie eine erweiterte Palette von Funktionen und Diensten ermöglichte.

Trotz der begeisterten Resonanz löste ChatGPT auch einige Kontroversen aus. Es lieferte teilweise fehlerhafte Antworten, 
insbesondere bei Aufgaben wie Schlussfolgerungen ziehen, Nuancen analysieren, Meinungen bewerten oder Vorhersagen treffen. 
Pädagogen weltweit äußerten Bedenken hinsichtlich des Einsatzes von ChatGPT im Bildungsbereich, auch an Universitäten wurde 
der Einsatz kritisch diskutiert.

Trotz dieser Kontroversen schien ChatGPT bereit zu sein, die Erstellung von Inhalten im Internet zu revolutionieren. 
Webentwickler und Content-Ersteller nutzten ChatGPT zunehmend als Recherche- und Schreibhilfe für Website-Texte.

Im März 2023 brachte OpenAI eine neue Version heraus, bekannt als GPT-4. Ein bedeutender Unterschied zu früheren Versionen 
bestand darin, dass GPT-4 Eingaben sowohl in Text- als auch in Bildformaten akzeptierte. Dies ermöglichte dem Chatbot, Daten 
aus Diagrammen, Grafiken und Screenshots zu interpretieren. Zudem machte GPT-4 deutlich weniger Denkfehler und sachliche Fehler, 
auch "Halluzinationen" genannt, als das zuvor verwendete GPT-3.5-Modell. Am Ende des Jahres hatte sich ChatGPT weiterentwickelt 
und konnte beispielsweise Bilder analysieren, Sprachansagen verarbeiten und gesprochene Antworten geben.

Im Mai 2024 kündigte OpenAI ein aktualisiertes Modell namens ChatGPT-4o an, das schnellere Ergebnisse sowie verbesserte 
Text- und Audiofunktionen versprach. Dieses Modell umfasste auch ein neues Konversations-KI-System namens ``Sky''\cite{GrundlagenChatGPT}.

\subsection{Google Gemini} \index{Google Gemini} \label{Google Gemini}

Im Dezember 2023 stellte Google eine generative Künstliche Intelligenz mit dem Namen Google Gemini vor. Sie wurde von Google DeepMind 
entwickelt und ist laut Aussage von Google das größte, leistungsstärkste und vielseitigste große Sprachmodell (LLM), das bisher von 
Google entwickelt und realisiert wurde. In der ursprünglichen Ankündigung wurde das KI-Sprachmodell unter dem Namen Gemini vorgestellt. 
Im Februar 2024 entschied Google, auch den bisher als Bard bekannten Chatbot in Gemini umzubenennen. Damit ist Gemini mittlerweile sowohl
der Name des Google Chatbots als auch des zugrundeliegenden Sprachmodells.

Bei Nachfrage an Gemini, ob es einen Infotext über sich erstellen kann, erhält man die Antwort in Abbildung \ref{InfotextGemini1} und Abbildung \ref{InfotextGemini2}

\begin{figure}
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
    \textbf{Prompt: Erstell mir einen Infotext über dich für meine Bachelorarbeit}\\ 
        \textbf{Was ist Gemini?}\\
        Gemini ist ein Large Language Model (LLM) von Google AI, das mit einem riesigen Datensatz aus Text und Code 
        trainiert wurde. Es kann Text generieren, Sprachen übersetzen, verschiedene Arten von kreativen Inhalten schreiben 
        und Ihre Fragen auf informative Weise beantworten. Gemini befindet sich noch in der Entwicklung, hat aber bereits gelernt,
        viele Arten von Aufgaben auszuführen, einschließlich:
        \begin{itemize}
            \item Befolgen Sie Anweisungen und erledigen Sie Aufgaben sorgfältig.
            \item Beantworten Sie Ihre Fragen umfassend und informativ, auch wenn sie offen, herausfordernd oder seltsam sind.
            \item Generieren Sie verschiedene kreative Textformate, wie Gedichte, Codes, Skripte, Musikstücke, E-Mails, Briefe usw. 
                  Ich werde mein Bestes tun, um alle Ihre Anforderungen zu erfüllen.
        \end{itemize}
        \textbf{Technische Details}\\
        Gemini basiert auf der Transformer-Architektur und wird mit einem massiven Datensatz aus Text und Code trainiert. 
        Es verwendet eine Vielzahl von Techniken, um seine Leistung zu verbessern, einschließlich:
        \begin{itemize}
            \item \textbf{Aufmerksamkeit:} Ermöglicht es Gemini, sich auf die relevantesten Teile einer Eingabe zu konzentrieren.
            \item \textbf{Beam Search:} Ermöglicht Gemini, die besten möglichen Ausgaben zu generieren.
            \item \textbf{Multitasking:} Ermöglicht Gemini, mehrere Aufgaben gleichzeitig zu lernen und auszuführen.
        \end{itemize}
        \textbf{Anwendungen}\\
        Gemini kann für eine Vielzahl von Anwendungen eingesetzt werden, einschließlich:
        \begin{itemize}
            \item \textbf{Generierung von kreativen Inhalten:} Gemini kann verwendet werden, um Gedichte, Codes, Skripte, Musikstücke, 
            E-Mails, Briefe usw. zu generieren.
            \item \textbf{Sprachübersetzung:} Gemini kann verwendet werden, um Text von einer Sprache in eine andere zu übersetzen.
            \item \textbf{Beantwortung von Fragen:} Gemini kann verwendet werden, um Ihre Fragen umfassend und informativ zu beantworten, 
            auch wenn sie offen, herausfordernd oder seltsam sind.
            \item \textbf{Zusammenfassen von Texten:} Gemini kann verwendet werden, um lange Textpassagen zu zusammenfassen.
            \item \textbf{Schreiben verschiedener Arten von kreativen Textformaten:} Gemini kann verwendet werden, um verschiedene Arten von 
            kreativen Textformaten zu schreiben, wie Gedichte, Codes, Skripte, Musikstücke, E-Mails, Briefe usw.
        \end{itemize}
    \vfill
    \end{tcolorbox}
    \caption{Quelle: Gemini}
    \label{InfotextGemini1}
\end{figure}

\begin{figure} 
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        \textbf{Ethische Überlegungen}\\
        Es ist wichtig, Gemini verantwortungsvoll und ethisch zu nutzen. Zu den ethischen Überlegungen, die bei der Verwendung von Gemini zu beachten sind, gehören:
        \begin{itemize}
            \item \textbf{Vermeidung von Vorurteilen:} Gemini wird mit einem riesigen Datensatz aus Text und Code trainiert. Dieser Datensatz 
            kann Vorurteile enthalten, die sich in den Ausgaben von Gemini widerspiegeln können. Es ist wichtig, sich dieser Vorurteile bewusst 
            zu sein und Maßnahmen zu ergreifen, um sie zu mindern.
            \item \textbf{Vermeidung von Schadenszufügung:} Gemini kann verwendet werden, um schädlichen Text zu generieren, z. B. Hassreden 
            oder Gewaltandrohungen. Es ist wichtig, Gemini nicht zu verwenden, um anderen Schaden zuzufügen.
            \item \textbf{Respekt vor der Privatsphäre:} Gemini kann verwendet werden, um personenbezogene Daten zu generieren. Es ist wichtig, 
            Gemini nicht zu verwenden, um die Privatsphäre anderer zu verletzen.
        \end{itemize}
        \textbf{Fazit}\\
        Gemini ist ein leistungsstarkes Tool, das für eine Vielzahl von Anwendungen eingesetzt werden kann. Es ist jedoch wichtig, Gemini verantwortungsvoll und ethisch zu nutzen.
    \vfill
    \end{tcolorbox}
    \caption{Quelle: Gemini}
    \label{InfotextGemini2}
\end{figure}

Gemini 1.0 wurde in drei verschiedenen Größen optimiert: Gemini Ultra als das größte und leistungsstärkste Modell 
für hochkomplexe Aufgaben, Gemini Pro als das beste Modell zur Anwendung in einem breiten Aufgabenspektrum und Gemini 
Nano als das effizienteste Modell für Aufgaben, die direkt auf dem Gerät verarbeitet werden.

Die Gemini-Modelle sind von Grund auf multimodal konzipiert, was bedeutet, dass sie mit verschiedenen Arten von 
Informationen umgehen können. Gemini ist in der Lage, Texte, Programmcode, Bilder, Videos, Audioinformationen und 
deren Kombinationen zu analysieren, zu verstehen, zu kombinieren und zu generieren. Da Gemini auch mit Skizzen und 
handgeschriebenem Text umgehen kann, eignet es sich für den Einsatz in Fachbereichen wie Mathematik oder Physik und 
anderen. Im Programmierbereich werden gängige Programmiersprachen wie Python, Java, C++ oder Go unterstützt. Gemini 
kann Programmcode analysieren, kommentieren und auch generieren. Dadurch steht Gemini in Konkurrenz zu anderen LLMs 
wie den GPT-Sprachmodellen von Open AI. Gemini soll jedoch die Konkurrenzprodukte in vielen Benchmarks deutlich übertreffen.

Gemini baut auf den ebenfalls von Google entwickelten Sprachmodellen LaMDA und PaLM 2 auf. Wie üblich für 
LLMs (Large Language Models) basiert auch Gemini auf einer Transformer-Architektur. Google hat die Architektur des 
Modells zur Skalierung der Trainingsfähigkeiten optimiert und mit einem Multi-Query-Aufmerksamkeitsmechanismus ausgestattet. 
Die unterstützte Kontextlänge beträgt 32.000 Tokens und in der Version 1.5 bis zu einer Million Tokens. Gemini wurde mit 
Daten verschiedener Modalitäten trainiert, und als Trainingsplattform verwendete Google Rechner-Cluster und Tensor 
Processing Units (TPUs) der neuesten Generation v4 und v5 als KI-Beschleuniger.

Google hat begonnen, die KI in zahlreiche eigene Produkte zu integrieren, um die Fähigkeiten der Websuche, des 
Chrome-Browsers, des Gmail-Services, verschiedener Entwicklungstools und anderer Produkte und Services zu verbessern 
und zu erweitern. Mitte Februar 2024 stellte Google Gemini 1.5 und 1.5 Pro vor, welche bis zu eine Million Tokens 
verarbeiten können. Diese neuen Versionen sollen die Benchmark-Ergebnisse der Vorgängerversion deutlich übertreffen \cite{GrundlagenGemini}.

\subsection{Le Chat} \index{Le Chat} \label{Le Chat}

Le Chat ist ein, von dem französischem KI-Startup Mistral AI veröffentlichter Chatbot. Mistral AI startete mit  
seinen frei verwendbaren Sprachmodellen, also auf der Grundlage von Open Source, erfolgreich durch. Nun  
hat Mistral AI sein bislang größtes Modell 'Mistral Large' veröffentlicht. Diesmal allerdings nicht auf der  
Basis von Open Source, sondern ausschließlich über die eigene Webseite und der KI-Infrastruktur Microsoft  
Azure. Es lassen sich allerdings API-Keys für Programmierschnittstellen erstellen, um z.B. Mistral Large über  
seinen eigenen Server laufen zu lassen und so für andere User auf der eigenen Homepage verfügbar zu machen.  
Mit Mistral Large wurde auch Le Chat veröffentlicht, welcher aktuell kostenfrei verwendet werden kann.
Le Chat bietet derzeit noch sehr wenige Funktionen an. Es stehen Lediglich Texteingabe und -ausgabe zur Verfügung.  
Die Datengrundlage reicht nur bis 2021, weshalb es auch hier, für die Jahre 2022 bis heute, zu der Problematik der  
Halluzination kommen kann.
Grundsätzlich kann man zwischen drei Sprachmodellen auswählen: Large, Next und Small. Large bietet überlegene Denkfähigkeit,  
Next ist ein Prototyp-Modell für erhöhte Kürze und Small arbeitet schnell und kosteneffektiv \cite{GrundlagenLeChat}.

\section{Software Engineering Prozess}
Test Verweis auf Buch \cite{Sommerville10} Das ist ein Text.
\subsection{einzelne Phasen} \index{einzelne Phasen} \label{einzelne Phasen}
