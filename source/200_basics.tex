
\chapter{Grundlagen} \index{Grundlagen}

In diesem Kapitel wird erläutert, was LLM Tools sind, wie sie trainiert werden und wie sie funktionieren. Anschließend 
werden die einzelnen Tools ChatGPT, Google Gemini und Le Chat vorgestellt und deren Entwicklung beschrieben.\\

Im zweiten Teil des Kapitels wird der Software Engineering Prozess erklärt und erläutert, was dieser umfasst. 
Dabei wird als Softwareprozess ausschließlich das Wasserfallmodell betrachtet, da in dieser Arbeit nur mit diesem 
Modell gearbeitet wird.

\section{LLM Tools} \index{LLM Tools} \label{LLM Tools}

Unter LLM-Tools versteht man Sprachmodelle, die auf einem Large Language Model (LLM) basieren. Ein LLM ist ein 
Deep-Learning-Algorithmus, der mit sehr großen Datensätzen trainiert wird. Diese Modelle finden häufig Anwendung im 
Bereich des Natural Language Processing (NLP), wo sie verwendet werden, um Abfragen in natürlicher Sprache zu beantworten 
oder Ergebnisse zu liefern. LLMs können neue Inhalte verstehen, zusammenfassen, generieren und vorhersagen. Durch das Training 
sammeln LLMs Milliarden von Parametern, bei denen es sich um Variablen handelt, die im Modell angepasst werden, um neue 
Inhalte abzuleiten.\\
LLMs basieren auf einem Transformer-Modell, das Eingaben in Token umwandelt und dann gleichzeitig mathematische 
Gleichungen ausführt, um Beziehungen zwischen den Token zu ermitteln. Dadurch kann der Computer Muster erkennen, 
die auch ein Mensch wahrnehmen würde, wenn ihm die gleiche Frage gestellt wird. Zudem verwenden Transformer-Modelle 
Selbstaufmerksamkeitsmechanismen, die es dem Modell ermöglichen, schneller zu lernen als herkömmliche Modelle. 
Somit kann das Transformer-Modell verschiedene Teile der Sequenz oder den gesamten Kontext eines Satzes berücksichtigen, 
um Vorhersagen zu generieren.

Grundsätzlich bestehen LLMs aus vier neuronalen Netzwerkschichten: der wiederkehrenden Ebene, der Einbettungsebene, 
der Feedforward-Ebene und der Aufmerksamkeitsebene. Diese Schichten arbeiten zusammen, um den Eingabetext zu verarbeiten 
und Ausgabeinhalte zu generieren.\\
Die wiederkehrende Ebene dient dazu, die Wörter des Eingabetextes der Reihe nach zu interpretieren und die Beziehungen 
zwischen den Wörtern in einem Satz zu erfassen. Die Einbettungsebene erfasst die semantische und syntaktische Bedeutung 
der Eingabe, sodass das Modell den Kontext verstehen kann. Die Feedforward-Schicht besteht aus mehreren vollständig 
verbundenen Schichten, die die Eingabeeinbettungen transformieren. Dadurch ermöglichen diese Schichten dem Modell, 
Abstraktionen auf höherer Ebene zu verstehen und somit die Absicht des Benutzers mit der Texteingabe zu erfassen. Die 
Aufmerksamkeitsebene ermöglicht es dem Sprachmodell, sich auf einzelne Teile des Eingabetextes zu konzentrieren, die für 
die Aufgabe relevant sind, und dadurch die genausten Ausgaben zu generieren.

Damit ein großes Sprachmodell Texteingaben empfangen und eine Ausgabevorhersage generieren kann, muss es zunächst 
allgemein geschult und anschließend feinabgestimmt werden, um spezifische Aufgaben ausführen zu können. Für die 
Schulung werden riesige Datenmengen im Petabyte-Bereich benötigt. Das Training verläuft mehrstufig und beginnt in 
der Regel mit einem unbeaufsichtigten Lernansatz, bei dem das Modell mit unstrukturierten und unbeschrifteten Daten 
trainiert wird, da diese in größeren Mengen verfügbar sind. In dieser Phase leitet das Modell Beziehungen zwischen 
verschiedenen Wörtern und Konzepten ab.\\
Anschließend erfolgt die Schulung und Feinabstimmung durch eine Form des selbstüberwachten Lernens. Dabei wird eine 
Datenkennzeichnung durchgeführt, durch die das Modell verschiedene Konzepte besser und genauer identifizieren kann. 
Im nächsten Schritt durchläuft das LLM den transformatorischen neuronalen Netzwerkprozess im Rahmen des Deep Learning. 
Die Transformer-Modellarchitektur ermöglicht es dem LLM, mittels eines Selbstaufmerksamkeitsmechanismus Beziehungen 
und Verbindungen zwischen Wörtern und Konzepten zu erkennen, indem bestimmten Elementen (Token) Bewertungen zugewiesen 
werden, um die Beziehungen festzulegen.

Entscheidend über die Leistungsfähigkeit und die Qualität des Sprachmodells sind die Datensätze, welche zum trainieren
benutzt werden. Im folgenden wird auf die drei unterschiedliche LLM-Tools eingeganden, welche in dieser Arbeit näher 
untersucht werden \cite{GrundlagenLLM}. 

\subsection{ChatGPT} \index{ChatGPT} \label{ChatGPT}


ChatGPT wurde von OpenAI am 30. November 2022 veröffentlicht und entwickelte sich aufgrund seiner fortschrittlichen 
generativen KI-Fähigkeiten rasch zu einer internationalen Sensation. Wenn man ChatGPT fragt, ob es einen Infotext 
zu sich selbst erstellen kann, erhält man die Antwort in \autoref{InfotextChatGPT}

\begin{prompt} 
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
    \textbf{Prompt: Erstell mir einen Infotext über dich für meine Bachelorarbeit}\\ 

    ChatGPT ist ein fortschrittlicher KI-gestützter Sprachassistent, der auf der GPT-4-Architektur von OpenAI basiert. 
    Entwickelt im Rahmen der Forschung und Entwicklung im Bereich Künstliche Intelligenz, ist ChatGPT in der Lage, 
    natürliche Sprache zu verstehen und darauf zu antworten. Dies macht ihn zu einem vielseitigen Werkzeug für eine 
    Vielzahl von Anwendungen, von der Beantwortung alltäglicher Fragen bis hin zur Unterstützung bei komplexeren 
    Aufgaben wie dem Schreiben von Texten, der Generierung von Ideen und der Bereitstellung von Informationen.\\
    
    Die GPT-4-Architektur, auf der ChatGPT basiert, verwendet tiefes maschinelles Lernen, um menschliche Sprache zu 
    verarbeiten und zu erzeugen. Durch die Analyse großer Mengen an Textdaten kann das Modell Muster und Zusammenhänge 
    erkennen, die es ihm ermöglichen, kontextuell relevante und kohärente Antworten zu geben. Diese Fähigkeiten machen 
    ChatGPT zu einem nützlichen Instrument in Bereichen wie Bildung, Forschung, Kundenservice und mehr.\\
    
    Ein weiterer bemerkenswerter Aspekt von ChatGPT ist seine Fähigkeit, sich an eine Vielzahl von Themen anzupassen 
    und Informationen auf klare und präzise Weise zu vermitteln. Dies wird durch kontinuierliches Training und 
    Verbesserung des Modells erreicht, wobei sowohl technische Fortschritte als auch Nutzerfeedback berücksichtigt 
    werden.\\
    
    Zusammengefasst ist ChatGPT ein leistungsstarker und vielseitiger KI-Assistent, der durch seine fortschrittliche 
    Technologie und seine breite Anwendbarkeit einen wertvollen Beitrag in vielen Bereichen leistet.\\
    \vfill
    \end{tcolorbox}
    \caption{Infotext ChatGPT, Quelle: ChatGPT}
    \label{InfotextChatGPT}
\end{prompt}

Die Beta-Version der Plattform war zunächst kostenlos verfügbar, und OpenAI bot den Nutzern weiterhin eine kostenlose 
Basisversion an. Im Februar 2023 führte OpenAI ein kostenpflichtiges Abonnement ein, das unbegrenzten Zugriff auf ChatGPT 
sowie eine erweiterte Palette von Funktionen und Diensten ermöglichte.

Trotz der begeisterten Resonanz löste ChatGPT auch einige Kontroversen aus. Es lieferte teilweise fehlerhafte Antworten, 
insbesondere bei Aufgaben wie Schlussfolgerungen ziehen, Nuancen analysieren, Meinungen bewerten oder Vorhersagen treffen. 
Pädagogen weltweit äußerten Bedenken hinsichtlich des Einsatzes von ChatGPT im Bildungsbereich, auch an Universitäten wurde 
der Einsatz kritisch diskutiert.

Trotz dieser Kontroversen schien ChatGPT bereit zu sein, die Erstellung von Inhalten im Internet zu revolutionieren. 
Webentwickler und Content-Ersteller nutzten ChatGPT zunehmend als Recherche- und Schreibhilfe für Website-Texte.

Im März 2023 brachte OpenAI eine neue Version heraus, bekannt als GPT-4. Ein bedeutender Unterschied zu früheren Versionen 
bestand darin, dass GPT-4 Eingaben sowohl in Text- als auch in Bildformaten akzeptierte. Dies ermöglichte dem Chatbot, Daten 
aus Diagrammen, Grafiken und Screenshots zu interpretieren. Zudem machte GPT-4 deutlich weniger Denkfehler und sachliche Fehler, 
auch ``Halluzinationen'' genannt, als das zuvor verwendete GPT-3.5-Modell. Am Ende des Jahres hatte sich ChatGPT weiterentwickelt 
und konnte beispielsweise Bilder analysieren, Sprachansagen verarbeiten und gesprochene Antworten geben.

Im Mai 2024 kündigte OpenAI ein aktualisiertes Modell namens ChatGPT-4o an, das schnellere Ergebnisse sowie verbesserte 
Text- und Audiofunktionen versprach. Dieses Modell umfasst auch ein neues Konversations-KI-System namens ``Sky'' \cite{GrundlagenChatGPT}.

\subsection{Google Gemini} \index{Google Gemini} \label{Google Gemini}

Im Dezember 2023 stellte Google eine generative Künstliche Intelligenz mit dem Namen Google Gemini vor. Sie wurde von Google DeepMind 
entwickelt und ist laut Aussage von Google das größte, leistungsstärkste und vielseitigste große Sprachmodell (LLM), das bisher von 
Google entwickelt und realisiert wurde. In der ursprünglichen Ankündigung wurde das KI-Sprachmodell unter dem Namen Gemini vorgestellt. 
Im Februar 2024 entschied Google, auch den bisher als Bard bekannten Chatbot in Gemini umzubenennen. Damit ist Gemini mittlerweile sowohl
der Name des Google Chatbots als auch des zugrundeliegenden Sprachmodells.

Bei Nachfrage an Gemini, ob es einen Infotext über sich erstellen kann, erhält man die Antwort in \autoref{InfotextGemini1} und \autoref{InfotextGemini2}.

\begin{prompt}
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
    \textbf{Prompt: Erstell mir einen Infotext über dich für meine Bachelorarbeit}\\ 
        \textbf{Was ist Gemini?}\\
        Gemini ist ein Large Language Model (LLM) von Google AI, das mit einem riesigen Datensatz aus Text und Code 
        trainiert wurde. Es kann Text generieren, Sprachen übersetzen, verschiedene Arten von kreativen Inhalten schreiben 
        und Ihre Fragen auf informative Weise beantworten. Gemini befindet sich noch in der Entwicklung, hat aber bereits gelernt,
        viele Arten von Aufgaben auszuführen, einschließlich:
        \begin{itemize}
            \item Befolgen Sie Anweisungen und erledigen Sie Aufgaben sorgfältig.
            \item Beantworten Sie Ihre Fragen umfassend und informativ, auch wenn sie offen, herausfordernd oder seltsam sind.
            \item Generieren Sie verschiedene kreative Textformate, wie Gedichte, Codes, Skripte, Musikstücke, E-Mails, Briefe usw. 
                  Ich werde mein Bestes tun, um alle Ihre Anforderungen zu erfüllen.
        \end{itemize}
        \textbf{Technische Details}\\
        Gemini basiert auf der Transformer-Architektur und wird mit einem massiven Datensatz aus Text und Code trainiert. 
        Es verwendet eine Vielzahl von Techniken, um seine Leistung zu verbessern, einschließlich:
        \begin{itemize}
            \item \textbf{Aufmerksamkeit:} Ermöglicht es Gemini, sich auf die relevantesten Teile einer Eingabe zu konzentrieren.
            \item \textbf{Beam Search:} Ermöglicht Gemini, die besten möglichen Ausgaben zu generieren.
            \item \textbf{Multitasking:} Ermöglicht Gemini, mehrere Aufgaben gleichzeitig zu lernen und auszuführen.
        \end{itemize}
        \textbf{Anwendungen}\\
        Gemini kann für eine Vielzahl von Anwendungen eingesetzt werden, einschließlich:
        \begin{itemize}
            \item \textbf{Generierung von kreativen Inhalten:} Gemini kann verwendet werden, um Gedichte, Codes, Skripte, Musikstücke, 
            E-Mails, Briefe usw. zu generieren.
            \item \textbf{Sprachübersetzung:} Gemini kann verwendet werden, um Text von einer Sprache in eine andere zu übersetzen.
            \item \textbf{Beantwortung von Fragen:} Gemini kann verwendet werden, um Ihre Fragen umfassend und informativ zu beantworten, 
            auch wenn sie offen, herausfordernd oder seltsam sind.
            \item \textbf{Zusammenfassen von Texten:} Gemini kann verwendet werden, um lange Textpassagen zu zusammenfassen.
            \item \textbf{Schreiben verschiedener Arten von kreativen Textformaten:} Gemini kann verwendet werden, um verschiedene Arten von 
            kreativen Textformaten zu schreiben, wie Gedichte, Codes, Skripte, Musikstücke, E-Mails, Briefe usw.
        \end{itemize}
    \vfill
    \end{tcolorbox}
    \caption{Infotext Gemini 1, Quelle: Gemini}
    \label{InfotextGemini1}
\end{prompt}

\begin{prompt} 
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        \textbf{Ethische Überlegungen}\\
        Es ist wichtig, Gemini verantwortungsvoll und ethisch zu nutzen. Zu den ethischen Überlegungen, die bei der Verwendung von Gemini zu beachten sind, gehören:
        \begin{itemize}
            \item \textbf{Vermeidung von Vorurteilen:} Gemini wird mit einem riesigen Datensatz aus Text und Code trainiert. Dieser Datensatz 
            kann Vorurteile enthalten, die sich in den Ausgaben von Gemini widerspiegeln können. Es ist wichtig, sich dieser Vorurteile bewusst 
            zu sein und Maßnahmen zu ergreifen, um sie zu mindern.
            \item \textbf{Vermeidung von Schadenszufügung:} Gemini kann verwendet werden, um schädlichen Text zu generieren, z. B. Hassreden 
            oder Gewaltandrohungen. Es ist wichtig, Gemini nicht zu verwenden, um anderen Schaden zuzufügen.
            \item \textbf{Respekt vor der Privatsphäre:} Gemini kann verwendet werden, um personenbezogene Daten zu generieren. Es ist wichtig, 
            Gemini nicht zu verwenden, um die Privatsphäre anderer zu verletzen.
        \end{itemize}
        \textbf{Fazit}\\
        Gemini ist ein leistungsstarkes Tool, das für eine Vielzahl von Anwendungen eingesetzt werden kann. Es ist jedoch wichtig, Gemini verantwortungsvoll und ethisch zu nutzen.
    \vfill
    \end{tcolorbox}
    %\addtocounter{figure}{-1}
    \caption{Infotext Gemini 2, Quelle: Gemini}
    \label{InfotextGemini2}
\end{prompt}

Gemini 1.0 wurde in drei verschiedenen Größen optimiert: Gemini Ultra als das größte und leistungsstärkste Modell 
für hochkomplexe Aufgaben, Gemini Pro als das beste Modell zur Anwendung in einem breiten Aufgabenspektrum und Gemini 
Nano als das effizienteste Modell für Aufgaben, die direkt auf dem Gerät verarbeitet werden.

Die Gemini-Modelle sind von Grund auf multimodal konzipiert, was bedeutet, dass sie mit verschiedenen Arten von 
Informationen umgehen können. Gemini ist in der Lage, Texte, Programmcode, Bilder, Videos, Audioinformationen und 
deren Kombinationen zu analysieren, zu verstehen, zu kombinieren und zu generieren. Da Gemini auch mit Skizzen und 
handgeschriebenem Text umgehen kann, eignet es sich für den Einsatz in Fachbereichen wie zum Beispiel Mathematik oder Physik. 
Im Programmierbereich werden gängige Programmiersprachen wie Python, Java, C++ oder Go unterstützt. Gemini 
kann Programmcode analysieren, kommentieren und auch generieren. Dadurch steht Gemini in Konkurrenz zu anderen LLMs 
wie den GPT-Sprachmodellen von Open AI. Gemini soll jedoch die Konkurrenzprodukte in vielen Benchmarks deutlich übertreffen.

Gemini baut auf den ebenfalls von Google entwickelten Sprachmodellen LaMDA und PaLM 2 auf. Wie üblich für 
LLMs (Large Language Models) basiert auch Gemini auf einer Transformer-Architektur. Google hat die Architektur des 
Modells zur Skalierung der Trainingsfähigkeiten optimiert und mit einem Multi-Query-Aufmerksamkeitsmechanismus ausgestattet. 
Die unterstützte Kontextlänge beträgt 32.000 Tokens und in der Version 1.5 bis zu einer Million Tokens. Gemini wurde mit 
Daten verschiedener Modalitäten trainiert, und als Trainingsplattform verwendete Google Rechner-Cluster und Tensor 
Processing Units (TPUs) der neuesten Generation v4 und v5 als KI-Beschleuniger.

Google hat begonnen, die KI in zahlreiche eigene Produkte zu integrieren, um die Fähigkeiten der Websuche, des 
Chrome-Browsers, des Gmail-Services, verschiedener Entwicklungstools und anderer Produkte und Services zu verbessern 
und zu erweitern. Mitte Februar 2024 stellte Google Gemini 1.5 und 1.5 Pro vor, welche bis zu eine Million Tokens 
verarbeiten können. Diese neuen Versionen sollen die Benchmark-Ergebnisse der Vorgängerversion deutlich übertreffen \cite{GrundlagenGemini}.

\subsection{Le Chat} \index{Le Chat} \label{Le Chat}

\begin{prompt}
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        \textbf{Prompt: Erstell mir einen Infotext über Le Chat für meine Bachelorarbeit}
        \textbf{Einleitung}\\
        Le Chat ist ein fortschrittliches Sprachmodell, das auf künstlicher Intelligenz (KI) und maschinellem Lernen 
        basiert. Entwickelt von einem Team aus Experten für KI und Sprachverarbeitung, hat Le Chat die Fähigkeit, 
        menschliche Sprache zu verstehen, zu interpretieren und darauf zu reagieren, was es zu einem wertvollen 
        Werkzeug in verschiedenen Branchen macht.\\

        \textbf{Funktionsweise}\\
        Le Chat nutzt eine Kombination aus Techniken des Natural Language Processing (NLP) und des Deep Learning. NLP 
        ermöglicht es dem Modell, die Struktur und den Kontext der menschlichen Sprache zu verstehen, während Deep 
        Learning-Algorithmen verwendet werden, um Muster in den Daten zu erkennen und die Genauigkeit der Vorhersagen 
        zu verbessern.\\

        \textbf{Anwendungsbereiche}\\
        Le Chat kann in einer Vielzahl von Anwendungen eingesetzt werden. Einige der wichtigsten Anwendungsbereiche sind:
        \begin{itemize}
            \item \textbf{Kundenservice:} Le Chat kann als virtueller Assistent eingesetzt werden, um Kundenanfragen zu 
            beantworten, Produktempfehlungen auszusprechen und den Kunden bei der Lösung von Problemen zu unterstützen.
            \item \textbf{Bildung:} Le Chat kann als Tutor-System eingesetzt werden, um Schülern und Studenten bei der 
            Lösung von Aufgaben und beim Verständnis von komplexen Konzepten zu helfen.
            \item \textbf{Gesundheitswesen:} Le Chat kann als virtueller Gesundheitsassistent eingesetzt werden, um 
            Patienten bei der Verwaltung ihrer Medikamente zu unterstützen, Gesundheitstipps zu geben und in Notfällen 
            Erste Hilfe-Anweisungen bereitzustellen.
            \end{itemize}
        \textbf{Vorteile}\\
        Le Chat bietet eine Reihe von Vorteilen gegenüber herkömmlichen Sprachmodellen. Einige der wichtigsten Vorteile sind:
        \begin{itemize}
            \item \textbf{Verbesserte Genauigkeit:} Le Chat nutzt fortschrittliche Deep Learning-Algorithmen, um die 
            Genauigkeit der Vorhersagen zu verbessern und eine bessere Benutzererfahrung zu bieten.
            \item \textbf{Skalierbarkeit:} Le Chat kann leicht skaliert werden, um eine große Anzahl von Anfragen 
            gleichzeitig zu bearbeiten, was es zu einer idealen Lösung für Unternehmen mit hohem Kundenaufkommen macht.
            \item \textbf{Kosteneffizienz:} Le Chat kann als kosteneffiziente Alternative zu menschlichen 
            Kundenservice-Mitarbeitern eingesetzt werden, was zu erheblichen Einsparungen für Unternehmen führen kann.
            \end{itemize}
        \textbf{Fazit}\\
        Le Chat ist ein innovatives Sprachmodell, das die Fähigkeit hat, die Art und Weise, wie wir mit Maschinen 
        interagieren, zu revolutionieren. Mit seiner fortschrittlichen Technologie und seinen vielfältigen 
        Anwendungsmöglichkeiten ist Le Chat ein wichtiger Meilenstein in der Entwicklung der KI und ein Werkzeug, 
        das in Zukunft eine noch größere Rolle spielen wird.
        \vfill
    \end{tcolorbox}
    \caption{Infotext LeChat, Quelle: Le Chat}
    \label{InfotextLeChat}
\end{prompt}

In \autoref{InfotextLeChat} sieht man die Antwort die Le Chat gibt, wenn man ihn nach einem Infotext über sich 
fragt. Le Chat ist ein, von dem französischem KI-Startup Mistral AI veröffentlichter Chatbot. Mistral AI startete mit  
seinen frei verwendbaren Sprachmodellen, also auf der Grundlage von Open Source, erfolgreich durch. Nun  
hat Mistral AI sein bislang größtes Modell 'Mistral Large' veröffentlicht. Diesmal allerdings nicht auf der  
Basis von Open Source, sondern ausschließlich über die eigene Webseite und der KI-Infrastruktur Microsoft  
Azure. Es lassen sich allerdings API-Keys für Programmierschnittstellen erstellen, um z.B. Mistral Large über  
seinen eigenen Server laufen zu lassen und so für andere User auf der eigenen Homepage verfügbar zu machen.  
Mit Mistral Large wurde auch Le Chat veröffentlicht, welcher aktuell kostenfrei verwendet werden kann.
Le Chat bietet derzeit noch sehr wenige Funktionen an. Es stehen Lediglich Texteingabe und -ausgabe zur Verfügung.  
Die Datengrundlage reicht nur bis 2021, weshalb es auch hier, für die Jahre 2022 bis heute, zu der Problematik der  
Halluzination kommen kann.
Grundsätzlich kann man zwischen drei Sprachmodellen auswählen: Large, Next und Small. Large bietet überlegene Denkfähigkeit,  
Next ist ein Prototyp-Modell für erhöhte Kürze und Small arbeitet schnell und kosteneffektiv \cite{GrundlagenLeChat}.


\section{Software Engineering Prozess}

\begin{figure}
    \centering
    \includegraphics{pictures/Wasserfallmodell.PNG}
    \caption{Wasserfallmodell, Quelle: \cite{Sommerville10}}
    \label{Ablauf Wasserfallmodell}
\end{figure}

Software-Engineering ist eine technische Disziplin, die sich umfassend mit der Erstellung von Software beschäftigt, beginnend 
bei der Konzeption, über den Betrieb, bis hin zur Wartung. Die wesentlichen Aktivitäten im Software-Engineering umfassen die 
Softwarespezifikation, -entwicklung, -validierung und -weiterentwicklung. Die Arbeitsweise im Software-Engineering variiert 
je nach den spezifischen Umständen. Für bestimmte Softwaretypen kann daher ein kreativeres, weniger formelles Vorgehen angemessen 
sein. Im Mittelpunkt des Software-Engineerings steht somit die Auswahl der am besten geeigneten Methode. Dieser systematische 
Ansatz wird oft als Softwareprozess bezeichnet. Ein Softwareprozess besteht aus einer Abfolge von Aktivitäten, die zur Erstellung 
eines Softwareprodukts führen. Die vier grundlegenden Aktivitäten des Software-Engineerings sind in jedem Softwareprozess 
enthalten. Während der Arbeit am Projekt werden die Ergebnisse in unterschiedlichen Dokumenten festgehalten. Im folgenden 
wird kurz auf die einzelnen Dokumente eingegangen und deren Aufbau und Inhalt beschrieben.\\ 

\cite{Sommerville10}.

\subsection{Besprechungsprotokoll} \index{Besprechungsprotokoll} \label{Besprechungsprotokoll}

Alle Team- und Kundengespräche werden systematisch in Besprechungsprotokollen dokumentiert. Diese Protokolle enthalten 
Aufträge, Beschlüsse, Feststellungen und Informationen, die in Form von Texten, Bildern, Diagrammen usw. festgehalten 
werden. Aufträge müssen mit einem Fälligkeitsdatum und einem Verantwortlichen versehen sein, während Beschlüsse klar 
und unmissverständlich formuliert werden sollten. Im Rahmen der Anforderungsanalyse werden in Beschlüssen die 
Benutzeranforderungen erfasst. Feststellungen hingegen sind Beschlüsse, die keine Abstimmung benötigen, können 
aber ebenfalls Anforderungen an das System enthalten. Informationen bieten den Projektmitgliedern wichtige Hinweise. 
Dabei ist zu beachten, dass ein Besprechungsprotokoll keine Erlebniserzählung sein soll.\\

Der Aufbau eines Besprechungsprotokolls gestaltet sich wie folgt: Am Anfang stehen Datum, Thema, Verfasser, 
Teilnehmer und Verteiler. Anschließend wird eine Tabelle mit den Spalten Nummer, Art, Beschreibung, Termin und 
Verantwortlicher erstellt. Die Nummer stellt eine eindeutige ID im Protokoll dar. Die Art spezifiziert, ob es sich 
um einen Auftrag (=A), einen Beschluss (=B), eine Feststellung (=F) oder eine Information (=I) handelt. Die 
Beschreibung fasst den Auftrag, den Beschluss, die Feststellung oder die Information kurz und präzise zusammen. Der 
Termin gibt an, bis wann der Auftrag erledigt sein muss. Der Verantwortliche benennt die Person, die den Auftrag 
ausführen muss, den Beschluss gefasst hat oder die Feststellung bzw. die Information geliefert hat.

\subsection{Projekthandbuch} \index{Projekthandbuch} \label{Projekthandbuch}

Das Projekthandbuch dient dazu, die Projektmitglieder umfassend über das Projekt zu informieren, einschließlich der 
Vorgeschichte, Vertragsbasis, Grundlagen, Ziele, Ergebnisse und mehr. Es bietet zudem eine Übersicht über die 
Projektorganisation, wie z.B. die Teamaufstellung, das Berichtswesen und die Dokumentenablage, sowie über wesentliche 
Projektabläufe wie Änderungsverfahren, Risikomanagement und Aufwandsverfolgung. Ziel des Projekthandbuchs ist es, neuen 
Teammitgliedern den Einstieg zu erleichtern und auf wichtige Dokumente hinzuweisen, die für die Projektabwicklung 
notwendig sind. Damit fungiert das Projekthandbuch als zentrale Anlaufstelle für das Projekt.\\

Das Dokument beginnt mit einer Einleitung, die die Rahmenbedingungen klärt. Dieser Abschnitt enthält den Zweck des 
Dokuments, Hinweise zur Redaktion, in denen festgelegt wird, wer für das Dokument verantwortlich ist, sowie 
Informationen zum Verteiler, also wer bei Änderungen informiert werden muss.\\

Im Anschluss folgt die Projektbeschreibung, die die Rahmenbedingungen des Projekts darlegt. Dieser Teil enthält einen 
Abschnitt zur Vorgeschichte, in dem beschrieben wird, wie es zu dem Projekt kam. Ein weiterer Abschnitt bietet eine 
inhaltliche Kurzdarstellung des Projekts. Danach werden in einem Abschnitt zur Vertragsbasis der zeitliche 
Projektrahmen, die Anzahl der Teammitglieder und der Umfang der Bearbeiter-Stunden festgelegt. Es folgt eine 
Beschreibung des Projektergebnisses, in der festgelegt wird, welche Produkte geliefert werden müssen. Ein weiterer 
Abschnitt zu sonstigen Besonderheiten beschreibt informelle Ziele.\\

Ein nachfolgendes Kapitel verweist auf die Risikoliste.\\

Daraufhin folgt ein Kapitel zur Projektorganisation, das die Teamstruktur und die Kommunikationswege beschreibt. 
Dieses Kapitel beginnt mit dem Teamaufbau, in dem die Aufgabenverteilung und die E-Mail-Adressen der einzelnen 
Teammitglieder vermerkt sind. Anschließend wird die Zusammenarbeit mit den Kunden definiert. Danach folgt ein 
Abschnitt über regelmäßige Pflichtbesprechungen für die Teammitglieder.\\ %Danach wird beschrieben, ob das 
%Projekt besondere Softwarelizenzen benötigt. Nachfolgend gibt es ein Abschnitt zu Sicherheit wo beschrieben wird, 
%wie mit Sicherheitsaspekten wie Backup, Zugangskontrollen und Verschlüsselungen umgegangen wird. Als letztes gibt es ein 
%Abschnitt für Sonstige Spielregeln.

Das folgende Kapitel widmet sich der Planung und behandelt verschiedene Planungsaspekte. Der erste Abschnitt befasst 
sich mit dem Projektplan. Hier werden die festgelegten Meilensteine beschrieben, einschließlich der Startzeiten der 
einzelnen Aktivitäten, der parallelen Abläufe, der Abschlusszeiten der verschiedenen Tätigkeiten, der 
Entstehungszeitpunkte der Produkte und der möglichen Entscheidungspunkte.\\ %Der zweite 
%Abschnitt geht über die Restaufwandsschätzung. Bei diesem wird wöchentlich eine Schätzung abgegeben, damit der Aufwand nicht
%aus dem Ruder läuft. Dafür gibt es einen Verweis auf ein externes Dokument.

%Anschließend gibt es ein Kapitel zur Qualitätssicherung

%Danach kommt ein Kapitel zu Datenschutz

Anschließend folgt ein Kapitel zur Dokumentation und Ablage, in dem beschrieben wird, wie und wo Produkte bzw. 
Dokumente abgelegt werden. Es beginnt mit einem Abschnitt zum Dokumenteneingang und -ausgang, in dem festgelegt 
wird, wie mit extern eingehenden Informationen umgegangen wird und wie ausgehende Informationen protokolliert 
werden. Im zweiten Abschnitt wird die Ablage und Archivierung geregelt, wobei erläutert wird, wie die Daten im 
Projektarchiv zu organisieren sind und in welchen Verzeichnissen die jeweiligen Daten abgelegt werden.

%Als vorletztes Kapitel wird in der Referenzliste auf alle sonstigen existierenden Dokumente verwiesen, die mit der 
%Projektabwicklung in Zusammenhang stehen.

%Zuletzt wird in einem Abkürzungsverzeichnis und Glossar spezielle Abkürzungen und wichtige Begriffe erklärt. 

\subsection{Risikoliste} \index{Risikoliste} \label{Risikoliste}

Die Risikoliste ist ein zentrales Instrument, das dem gesamten Team einen umfassenden Überblick über bekannte Risiken 
und die entsprechenden Maßnahmen bietet. Der Projektleiter muss diese Risiken stets im Auge behalten, um eine 
fundierte Projektplanung sicherzustellen. Zusätzlich kann die Risikoliste dem Anforderungsanalysten bei der 
Identifikation von Anforderungen, dem Systemarchitekten bei der Wahl geeigneter technischer Lösungen und dem 
Testmanager bei der Entwicklung von Testfällen nützlich sein.

Der Inhalt der Risikoliste umfasst die Autoren des Dokuments, die Historie des Dokuments mit einer Zusammenfassung 
der Änderungen, die Liste der Risiken sowie eine Liste der möglichen Maßnahmen für jedes identifizierte Risiko. 
Die Historie enthält Spalten für Datum, Autor*in und Änderungen, um später vorgenommene Modifikationen leichter 
nachvollziehbar zu machen.

Die Risikoliste selbst setzt sich aus mehreren Attributen zusammen. Die Identifikationsnummer ist eine eindeutige 
Nummer zur Identifizierung des Risikos, während die Risikobezeichnung eine kurze Beschreibung des Risikos bietet. 
Eine ausführliche Darstellung des Risikos findet sich in der Spalte für die Risikobeschreibung. Das Datum beschreibt, 
wann das Risiko identifiziert wurde, und der Autor gibt an, wer das Risiko gemeldet hat. In der Spalte für Auswirkungen 
werden die möglichen Folgen des Risikos beschrieben. Die Risikowahrscheinlichkeit ist eine Schätzung der 
Eintrittswahrscheinlichkeit des Risikos, und der Risikoschaden oder das Risikoausmaß beschreibt das potenzielle 
Schadensausmaß, einschließlich eventueller Vertragsstrafen. Das Risikomaß berechnet sich aus der Multiplikation von 
Risikowahrscheinlichkeit und Risikoschaden. Die Risikoklasse ist eine Priorisierung der Risiken, typischerweise in 
Kategorien wie tolerierbar, unerwünscht, kritisch oder katastrophal. Schließlich wird für jedes Risiko ein Status 
festgelegt, der zwischen aktiv, eingetragen und geschlossen unterscheiden kann.

Die Maßnahmen zur Risikobewältigung umfassen ebenfalls mehrere Attribute. Zunächst wird der Typ der Maßnahme festgelegt, 
wobei zwischen Risiko verhindern, Risiko lindern oder minimieren, Risiko übertragen oder teilen und Risiko akzeptieren 
unterschieden werden kann. Eine detaillierte Beschreibung der Maßnahme folgt, und falls das Risiko den Status 
``geschlossen'' erhält, wird hier die Begründung eingetragen. Wenn eine Maßnahme nicht sofort eingeleitet werden soll, 
wird das Ereignis, das die Maßnahme auslöst, in der Trigger-Spalte definiert. Die verantwortliche Person, die für 
die Umsetzung der Maßnahme zuständig ist, wird ebenfalls eingetragen. Der geplante Termin gibt an, bis wann die 
Maßnahme abgeschlossen sein soll, und der Ist-Termin beschreibt den voraussichtlichen Abschluss basierend auf 
aktueller Einschätzung. Der geplante Aufwand gibt die geschätzten Kosten der Maßnahme an, während der Ist-Aufwand 
den aktuellen Aufwand widerspiegelt. Auch für die Maßnahme gibt es einen Status, bei dem man zwischen geplant, aktiv 
oder beendet wählen kann. Das letzte Attribut umfasst die Restrisikowahrscheinlichkeit, den Restrisikoschaden, das 
Restrisikomaß und die Restrisikoklasse. Dies sind die geschätzte Wahrscheinlichkeit, der geschätzte Schaden, das 
geschätzte Maß und die geschätzte Klasse des Restrisikos nach Durchführung der Maßnahmen.

\subsection{Anforderungsspezifikation} \index{Anforderungsspezifikation} \label{Anforderungsspezifikation}

Die Anforderungsspezifikation beschreibt formell, was das zu entwickelnde System leisten muss. Sie beschreibt was das 
System leisten soll, aber nicht wie das System dies umsetzt. Das wie ist Inhalt des Architekturdokuments. In der Praxis 
sind Anforderungen und Systementwurf nicht trennbar. Die Anforderungsspezifikation ist oft Bestandteil des Vertrags und 
muss daher so vollständig und eindeutig wie möglich sein.

Die Anforderungsspezifikation hilft zum einen dem Kunden oder Endbenutzer zu beurteilen, ob das System das Gewünschte 
leisten wird und wie das System später bedient werden muss und zum anderen wird Sie vom Projektmanager zur Erstellung 
des Angebots für das System und zur Planung des detaillierten Systementwicklungsprozesses verwendet. Ebenfalls hilft es 
den späteren Administratoren zu entscheiden, wie das System administriert werden muss. 