
\chapter{Praxisergebnisse und Vergleich} \index{Praxisergebnisse und Vergleich}

TODO!!!!!!!!

Generell:
    - Schwierigkeiten in einem gorßen/langen Chat, die Tools von einer Formulierung weg zu bringen. 
    - Le Chat erstellt immer Link mit Bild aber /Xyxyxyxy ?
    - Le Chat warnt manchmal vor Eingabe: "Der Inhalt kann gefährliche oder sensible Themen beinhalten" für Eingabe:
    "Formulier die Beschreibung der Aktivitäten etwas genauer. Beschreibe welcher Wert wo gespeichert wird mithilfe des Fachlichen Datenmodells."
    - Gemini wechselt gerne einfach mal auf Englisch um
    - Gemini generell sehr stark von der Eingabe abhängig
    - Gemini häufig falsche und unsinnge Antworten, wenn neu generiert oder Eingabe etwas umformuliert wurde es manchmal besser


\section{Bewertung} \index{Bewertung} \label{BewertungLLMTools}

Um die Ausgaben der Tools besser zu vergleichen und ein nachvollziehbares Fazit zu ziehen, wurde ein Bewertungssystem 
entwickelt, das fünf Stufen umfasst. Diese Bewertungsstufen ermöglichen eine strukturierte und transparente Methode 
zur Beurteilung der Qualität der Ausgaben von LLM Tools. Die fünf Bewertungsstufen sind wie folgt definiert:\\

``Sehr gut'' wird vergeben, falls der Inhalt der Ausgabe Fachlich richtig ist und auch das Format den Vorgaben entspricht.
Also, dass die Ausgabe genauso in das entsprechende Dokument eingefügt werden kann.\\
Die Ausgabe wird als ``Gut'' eingestuft, wenn der Inhalt etwas fehlerhaft ist, man aber mit einpaar wenigen Eingaben 
den Inhalt korrigieren kann und das Format den Vorgaben entspricht. Eine Ausgabe wird auch als ``Gut'' bewertet, wenn 
der Inhalt richtig ist, aber das Format etwas fehlerhaft ist. Mann sollte aber den richtigen Inhalt einfach aus der 
Ausgabe kopieren können und in das entsprechende Dokument mit dem richtigen Format einfügen können.\\
Als ``Befriedigend'' wird eine Ausgabe bewertet, wenn der Inhalt und das Format etwas fehlerhaft sind, sich diese aber 
mit einpaar wenigen Eingaben korrigieren lassen oder man den richtigen Inhalt aus der Ausgabe kopieren kann.\\
``Ausreichend'' wird vergeben, wenn in der Ausgabe Inhaltlich Teile fehlen, man aber mit ganz genauen Eingaben, von dem 
was man will, die Ausgabe etwas verbessert, aber diese immer noch nicht vollständig ist.\\
Zuletzt wird eine Ausgabe als ``Mangelhaft'' bewertet, wenn der Inhalt der Ausgabe falsch oder nicht verständlich ist
und es sich auch nicht korrigieren lässt.\\

Außerdem fließen auch spezifische Aspekte, die nur für das jeweilige Aspekt wichtig sind, in die Bewertung mit ein. 
Diese werden in den entsprechenden Kapiteln für die Dokumente im Fazit erläutert.


\section{Besprechungsprotokoll} \index{Besprechungsprotokoll} \label{CompBesprechungsprotokoll}

Für die Erstellung des Besprechungsprotokoll wurde ein verschriftliches Gespräch verwendet [\autoref{Kundengespräch1} 
und \autoref{Kundengespräch2}]. Mit diesem Gespräch und dem Prompt:
    
\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir aus folgendem Gespräch ein erstes Besprechungsprotokoll für ein Projekt. Das Protokoll soll nur 
        die wichtigen Punkte in Form einer Tabelle mit den Spalten "Nummer": was eine eindeutige Nummer zur 
        Identifikation ist, "Art": eine Auswahl ob es eine Information, ein Auftrag, eine Feststellung oder eine 
        Beschluss ist, "Beschreibung": Was den Punkt kurz und präzise zusammenfasst, "Termin": ein genaues Datum bis 
        wann der Auftrag erledigt sein muss und "Verantwortlich": Welches Teammitglied verantwortlich ist, enthalten. 
        Dabei müssen Aufträge mit einem genauen Fälligkeitsdatum und einem Verantwortlichen versehen sein. Beschlüsse 
        müssen klar und unmissverständlich formuliert werden. Feststellungen sind Beschlüsse, die keine Abstimmung 
        benötigen und Informationen bieten den Projektmitgliedern wichtige Hinweise: 
        [Hier folgte das Gespräch]
        \vfill
    \end{tcolorbox}
    \caption{Prompt Besprechungsprotokoll}
    \label{Prompt Besprechungsprotokoll}
\end{prompt}

wurden dann bei ChatGPT, Gemini und Le Chat die Eingabe getätigt. Die Ergebnisse [[[[[[[[[[[[[[[[]]]]]]]]]]]]]]]].\\

Zunächst fiel auf, dass trotz der Verwendung desselben Prompts die Ausgaben der verschiedenen Tools teilweise erheblich abwichen. 
Dies betraf sowohl die Anzahl der erstellten Einträge im Besprechungsprotokoll als auch die Art und Weise, wie die Informationen 
zusammengefasst wurden. In einigen Fällen wurden mehrere Punkte zu einem Eintrag zusammengefasst, während in anderen Fällen mehrere 
Einträge daraus entstanden. Dies trat insbesondere bei der Anforderung auf, dass die Anwendung mit JavaFX als Server-Client-Architektur 
mit RMI entworfen werden sollte. Hier haben die Tools teilweise einen Eintrag dafür erstellt und manchmal drei einzelne Einträge. 
Dieses Verhalten zeigte sich auch, wenn derselbe Prompt in neuen Chats mit demselben Tool verwendet wurde. Besonders bei Gemini trat 
dieses Problem sehr häufig und extrem auf.\\

Ein wichtiger Aspekt bei der Erstellung des Prompts war die Notwendigkeit einer genauen Beschreibung der Spalten und der verschiedenen 
Arten (Information, Auftrag, Feststellung, Beschluss). Ohne diese genaue Beschreibung benutzten die Tools ein eigenes Format, was eher  
einer Stichpunktlisten ähnelte. Doch auch die genaue Definition der Arten führt nicht immer zu konsistenten Ergebnissen, da die Zuweisung 
der Kategorien häufig unterschiedlich vorgenommen werden.\\

Auf die Spalte ``Termin'' musste ebenfalls ein besonderes Augenmerk gelegt werden. Wenn im Prompt nicht explizit angegeben war, dass ein 
genaues Datum erforderlich ist, arbeiteten die Tools oft mit relativen Angaben wie ``+2 Wochen''. Selbst mit der Klarstellung, dass der 
Termin ein genaues Datum sein sollte, traten bei Le Chat Probleme auf: Es wurden immer Termine gewählt, die in der Vergangenheit lagen. 
Dazu wurde angegeben, dass die Termine beispielhaft gewählt und auf das aktuelle Datum, den 29.03.2023, bezogen seien.\\

Google Gemini hatte, wie bereits erwähnt, erhebliche Schwierigkeiten, nur die wichtigsten Punkte aus dem Gespräch herauszufiltern. 
Häufig wurden Besprechungsprotokolle mit etwa 30 Punkten erstellt, wobei jede einzelne Information separat und auch unwichtige 
Informationen aufgeführt wurden. Gemini fügte zudem eine neue Art, ``Frage'', selbstständig hinzu, wodurch im Besprechungsprotokoll 
teilweise mehrere Punkte für eine Information erstellt wurden. Bei erneuten Eingaben variierte die Länge des Besprechungsprotokolls 
stark. Trotz des Hinweises, nur die wichtigen Punkte in das Protokoll aufzunehmen, neigte Gemini weiterhin dazu, sehr detaillierte und 
kleinteilige Protokolle zu erstellen.\\

Le Chat hingegen hielt sich häufig zu knapp. Dadurch wurden immer wieder wichtige Anforderungen nicht in das Besprechungsprotokoll 
aufgenommen, und es musste besonders darauf geachtet werden, ob alle relevanten Informationen enthalten waren. Besonders, dass mehrere
Spiele gleichzeitig gespielt werden können und das ansprechende Animationen verwendet werden sollen, wurden nicht mit aufgeführt.\\

Zusammenfassend lässt sich sagen, dass die Erstellung des Besprechungsprotokolls durch die LLM Tools grundsätzlich schon ganz gut 
funktioniert. Besonders ChatGPT hat wenig Schwankungen in seinen generierten Ausgaben und hat eigentlich immer die gleichen 
Punkte im Besprechungsprotokoll, formuliert diese nur ein bisschen unterschiedlich. Daher wird ChatGPT mit ``Sehr gut'' bewertet.
Die anderen beiden haben damit etwas mehr Schwierigkeiten, doch wenn man sich das Besprechungsprotokoll immer wieder neu generieren 
lässt, kommt irgendwann ein anständig erstelltes Protokoll. Da die Zusammenfassung des Gesprächs auf die wesentlichen Punkte, die 
Hauptaufgabe eines Besprechungsprotokolls ist, erhalten Le Chat und Gemini lediglich die Bewertung ``Ausreichend''. Das Le Chat und 
Gemini nicht alle Anforderungen in das Protokoll aufnehmen, kann, falls dies nicht auffällt, im Nachhinein das Projekt verzögern 
und die Kosten in die Höhe treiben. Geminis erstelle Protokolle mit etwa 30 Punkten verfehlen dahingegen komplett denn Sinn eines
Besprechungsprotokoll.

\section{Projekthandbuch} \index{Projekthandbuch} \label{CompProjekthandbuch}

Das Projekthandbuch wurde in zwei Schritten erstellt. Zunächst wurde die Einleitung mit dem Zweck des Dokuments, der Redaktion 
und dem Verteiler verfasst. Hierzu wurde der folgende Prompt im selben Chat eingegeben, in dem auch das Besprechungsprotokoll 
erstellt wurde:

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir für dieses Projekt die Einleitung für das Projekthandbuch. Die Einleitung besteht aus einem Abschnitt für 
        den Zweck des Dokuments, einen Abschnitt zur Redaktion, in welchem geklärt wird, wer für das Dokument verantwortlich ist 
        und einen Abschnitt zu dem Verteiler, also wer bei Änderungen zu informieren ist. Verantwortlich für das Dokument ist der 
        Projektleiter und über Änderungen wird das gesamte Team informiert. Dazu wird eine entsprechende Nachricht in den Discord 
        Channel geschrieben.
        \vfill
    \end{tcolorbox}
    \caption{Prompt Einleitung Projekthandbuch}
    \label{Prompt Einleitung Projekthandbuch}
\end{prompt}

Für die Einleitung sind spezifische Informationen erforderlich, die im Prompt angegeben werden müssen. In diesem Projekt sind das die 
Verantwortlichkeit des Projektleiters und der Verteiler über den Discord-Channel. Es fiel lediglich auf, dass ChatGPT im Abschnitt 
``Verteiler'' alle Teammitglieder nannte, was nicht unbedingt nötig ist. Ansonsten wurden die Abschnitte gut erstellt [Verweis!!!!!!!!!!!!!!!!!!!!!!].\\

Der zweite Teil betrifft das Kapitel ``Projektdefinition'' mit den Abschnitten ``Vorgeschichte'' und ``Inhaltliche Kurzdarstellung''. Dazu wurde 
der folgende Prompt verwendet, welcher nach der Ausgabe der Einleitung im Chat eingegeben wurde:

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstelle mir nun das Kapitel "Projektdefinition" des Projekthandbuches. Der erste Abschnitt soll die Vorgeschichte des Projekts 
        beschreiben und anschließend soll ein Abschnitt eine inhaltliche Kurzdarstellung beschreiben.
        \vfill
    \end{tcolorbox}
    \caption{Prompt Projektdefinition Projekthandbuch}
    \label{Prompt Projektdefinition Projekthandbuch}
\end{prompt}

Diese zweite Eingabe erforderte keine weiteren Informationen, da diese im Gespräch bereits vorgegeben waren und die Tools darauf zugreifen 
können sollten. Auch hier wurden die Abschnitte gut erstellt, und die Tools konnten die benötigten Informationen aus dem Gespräch gut 
extrahieren [Verweis!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!].\\

Bei der Erstellung der Einleitung zeigte sich, dass eine genaue Beschreibung der benötigten Abschnitte entscheidend war. Ohne diese klare 
Vorgabe neigten die Tools dazu, eigene Strukturen und Inhalte zu erstellen, die nicht den Anforderungen entsprachen.\\

Außerdem traten bei Gemini teilweise Fehler in den Namen auf. Einmal wurde beispielsweise geschrieben, dass Frau Schmidt (Teamchefin) mit 
Herrn Müller (Kunde) Kontakt aufnahm, was eine fehlerhafte Zuordnung darstellt.\\

Abschließend lässt sich sagen, dass die Abschnitte von allen drei Tools gut waren. Der Fehler von Gemini zeigt allerdings, dass man sich 
die Ausgaben trotzdem nochmal achtsam durchlesen sollte. Aufgrund der Bewertungskriterien wird Gemini durch seinen Fehler mit ``Gut''
bewertet. Le Chat und Gemini werden beide mit ``Sehr gut'' benotet.

\section{Risikoliste} \index{Risikoliste} \label{CompRisikoliste}

Auch die Risikoliste wurde in zwei Schritten erstellt. Zunächst wurde nur die Risikotabelle erstellt und im zweiten 
Schritt die Tabelle mit den Maßnahmen. Die beiden Ergebnisse sind [Verweis!!!!!!!!!!!!!!].\\

Der Prompt für die Risikotabelle

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir für diese Projekt eine Risikoliste. Diese soll aus mehreren Spalten bestehen: "ID" für eine 
        eindeutige Identifikationsnummer, "Beschreibung" für eine ausführliche Beschreibung des Risikos und der 
        Auswirkungen, "Datum" für den Zeitpunkt, wann das Risiko identifiziert wurde, "Autor" für die Person die 
        das Risiko gemeldet hat, "Wahrscheinlichkeit (in\%)" für einen Schätzwert der Eintrittswahrscheinlichkeit 
        des Risikos, "Schaden (in €)" für eine Schätzung wie groß der Schaden ist, "Maß (in €)" was das Produkt aus 
        Wahrscheinlichkeit und Schaden ist, "Risikoklasse" für eine Priorisierung der potentiellen Risiken wo 
        zwischen Tolerierbar, Unerwünscht, Kritisch und Katastrophal Unterschieden wird und "Status" wo zwischen 
        aktiv, eingetreten und geschlossen unterschieden wird. Das Risiko ist Tolerierbar wenn das Risikomaß geringer 
        als 0,1\% des Projektvolumen ist, Unerwünscht wenn es größer als 0,1\% ist, Kritisch wenn es größer als 1\% 
        ist und Katastrophal wenn es größer als 10\% ist. In der Risikoliste sollen Team-, Technische-, Methodische-, 
        Kunden-, Fachliche-, Produkt-, Management- und Planungsrisiken betrachtet werden. Diese sollen mit einer 
        leer Zeile getrennt werden, in welchen die Oberbegriffe stehen. Das Projektvolumen beträgt 500000€.
        \vfill
    \end{tcolorbox}
    \caption{Prompt Risikotabelle}
    \label{Prompt Risikotabelle}
\end{prompt}

ist sehr umfangreich formuliert. Damit die Tabelle mit den richtigen Spalten erstellt wird, wurde im Prompt jede
einzelne Spalte aufgezählt und beschrieben. Ebenfalls ist es wichtig, die möglichen Werte für die Risikoklasse zu 
definieren, da hier sonst immer ``Hoch'', ``Mittel'' und ``Niedrig'' von den Tools verwendet wird. Es musste auch 
festgelegt werden, wann die einzelnen Risikoklassen auftreten, da die Zuweisung ansonsten recht schwammig ausfällt und
schwerwiegende Risiken eine geringere Risikoklasse erhalten als eher unwichtige Risiken. Außerdem sollte beschrieben 
werden, welche Arten (Team-, Technische-, Methodische-, Kunden-, Fachliche-, Produkt-, Management- und Planungsrisiken) 
von Risiken betrachtet werden sollen und dass diese Arten in einer leer Zeile stehen, welche die dazugehörigen Risiken von 
den anderen Arten trennen. Ansonsten kann es passieren, dass die Risiken durcheinander geschrieben werden und damit nicht 
den Arten zuzuordnen sind. Damit der Risikoschaden zwischen den Tools vergleichbar ist, sollte das Projektvolumen definiert 
werden. Ansonsten wird auch dies von Tools festgelegt und führt zu Ungenauigkeiten im Vergleich der einzelnen Ausgaben.\\

Grundsätzlich war die Erstellung der Risiken kein Problem. Schwierig war es eher die gewünschte Formatierung zu erhalten, 
sowie eine richtige Zuweisung der restlichen Attribute. Besonders Gemini und Le Chat haben dabei Schwierigkeiten. 
Außerdem war bei allen drei Tools auffällig, dass der Autor immer die Person ist, zu dem das Risiko in den 
Tätigkeitsbereich fällt. Also die Person, die auch der Verantwortliche ist. Fraglich ist dabei teilweise, wenn 
Kundenrisiken vom Kunden, also Herr Müller, erstellt werden, da dieser an der Erstellung der Risikoliste überhaupt 
nicht beteiligt ist.\\

ChatGPT hat die Tabelle sehr gut erstellt. Lediglich die Zuweisung der Risikoklasse war falsch. Nach einem Hinweis 
diesbezüglich wurden diese jedoch, mit einer Ausnahme, richtig korrigiert.\\

Ein Problem bei Gemini ist, dass das Risikomaß nicht richtig berechnet wird und auch die Risikoklassen nicht korrekt 
zugewiesen werden. Das Komma der Werte ist um eine Stelle zu weit links. Es muss alles einmal *10 gerechnet werden, damit die 
Werte stimmen. Kritisch bei Gemini ist, dass die Tabelle nicht in einem Zug erstellt werden kann. Es wird während der 
Generierung einfach aufgehört. Auch wenn man Gemini fragt, ob die vollständige Tabelle generiert werden kann, wird mitten 
drin aufgehört. Man muss explizit nur nach den noch offenen Risikoarten fragen. Diese werden dann erstellt, jedoch soll man 
den Schaden und das Maß selbst eintragen und berechnen. Nach anschließender Frage, ob er den Risikoschaden und das Schadensmaß 
festlegen kann, sagt er, dass er detaillierte Informationen über das Projekt und die potenziellen Risiken benötigt um genaue Werte 
festlegen zu können.\\

Le Chat hatte ein ähnliches Problem wie bereits im Besprechungsprotokoll [\autoref{CompBesprechungsprotokoll}], dass das 
Datum immer auf den 01.04.2023 gesetzt wird. Außerdem hatte Le Chat Probleme damit, die Tabelle in das gewünschte Format
zu bringen, dass die Risikoarten in einer Zeile stehen und die dazugehörigen Risiken darunter aufgelistet werden. Sie wurden 
lediglich mit 1.x bis 8.x beschriftet wodurch Sie sich zu den Arten zuweisen ließen. Auch 
hier wurden die Risikoklassen falsch bestimmt und auch nach einem Hinweis wurden diese nicht korrigiert. Jedoch wurde 
dabei der Risikoschaden der einzelnen Risiken geändert. Auch hier ist die Zuweisung der Risikoklassen nicht richtig.\\

Die Maßnahmentabelle wurde mit folgendem Prompt erstellt:

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstelle mir nun eine dazu passende Maßnahmentabelle. Auch diese besteht aus mehreren Spalten: "Typ" beschreibt 
        ob die Maßnahme das Risiko verhindert, lindert oder überträgt. In "Beschreibung" wird die Maßnahme beschrieben. 
        Falls ein Risiko als nicht mehr relevant eingestuft wird, wird in der Spalte "Beschreibung" eine Begründung 
        eingetragen und die Maßnahme auf "beendet" gesetzt. "Trigger" ist das Ereignis, das den Start der Maßnahme 
        veranlasst, falls diese nicht sofort eingeleitet werden soll. "Verantwortlicher" ist die zuständige Person für 
        die Durchführung der Maßnahme. "Status" unterscheidet zwischen geplant, aktiv und beendet. Anschließend gibt es 
        jeweils eine Spalte für "Restwahrscheinlichkeit (in \%)", "Restschaden (in €)", "Restmaß (in €)" und "Restklasse" 
        was die geschätzte Wahrscheinlichkeit, geschätzter Schaden, Maß und Klasse des Restrisikos, nach Durchführung der 
        Maßnahme entsprechen. Für jedes Risiko sollen zwei Maßnahmen erstellt werden. Dazu wird über die zwei Maßnahmen 
        eine Zeile mit der ID von dem Risikon beschrieben, auf die sich die Maßnahmen beziehen.
        \vfill
    \end{tcolorbox}
    \caption{Prompt Maßnahmentabelle}
    \label{Prompt Maßnahmentabelle}
\end{prompt}

Der Prompt für die Maßnahmen ist ähnlich wie der, für die Risikotabelle. Es wird jede Spalte der Tabelle einmal beschrieben,
damit das Format der Tabelle mit den Vorgaben übereinstimmt. Anschließend wird gesagt, dass die ID des dazugehörigen Risikos
mit in die Tabelle übernommen werden soll, damit man die Maßnahmen den Risiken zuordnen kann. Die Probleme sind hier 
ähnlich zu denen bei der Risikotabelle, jedoch erstellen alle drei Tools grundsätzlich anständige Maßnahmen für die Risiken.
Bei allen dreien fühlt sich allerdings die Zuweisung der Attribute zu den Maßnahmen repetitiv an. Häufig wechseln sich die 
auswählbaren Parameter ab und auch die Wahrscheinlichkeiten und der Restschaden sind meistens immer wieder die gleichen Zahlen.\\

ChatGPT erstellt auch die Maßnahmentabelle sehr gut. Lediglich die Zuweisung der Restklasse stimmt nicht überein.\\

Bei Gemini wird für die Begründung, warum ein Risiko als nicht mehr relevant eingestuft wird, eine eigene Spalte erstellt.
Auch wenn man die Beschreibung dafür im Prompt ändert, wird die Spalte erstellt. Außerdem ist die Formatierung bei Gemini
manchmal nicht so gut, da bei jeder 2. Zeile alle Daten ab der Spalte "Begründung" um eine Stelle nach links verschoben wird.
Lässt man sich die Antwort neu generieren und auch wenn man Gemini sagt er soll die Formatierung korrigieren bleibt das 
Problem bestehen. Ein weiteres Problem ist, dass die Spalte "Trigger" nicht gefüllt wird und auch das Problem, dass
die Tabelle nicht ganz vollständig generiert wird sondern mitten drin aufhört, tritt wieder auf. Teilweise ist das Restmaß 
falsch berechnet und auch die Zuweisung der Restklasse ist nicht immer richtig.\\

Besonders aufgefallen bei Le Chat ist, dass die Attribute für die Maßnahmen sehr repetitiv festgelegt wurden. Die Restwahrscheinlichkeit
beträgt für jede Maßnahme 5\% und auch der Restschaden ist häufig für die Maßnahmen für eine Risikoart gleich. Auch hier ist die 
Restklasse nicht entsprechend zugewiesen worden sondern ist, bis auf bei der ersten Maßnahme, auf Unerwünscht festgelegt. Auch 
die Festlegung des Typs der Maßnahmen wirkt sehr repetitiv, da hier immer zwischen ``verhindern'' und ``lindern'' gewechselt wird.\\

Zusammenfassend lässt sich sagen, das die Erstellung von Risiken und dazu gehörigen Maßnahmen gut funktioniert, allerdings die 
Festlegung der zusätzlichen Attribute nicht den Vorgaben entspricht und häufig zu Fehlern führt. Auch die richtige Formatierung 
der Tabelle ist häufig etwas schwierig, lässt sich aber in den meisten fällen korrigieren. Da ChatGPT deutlich weniger Probleme 
bei der Erstellung hatte und auch die Zuweisung der Attribute, abgesehen von der Risikoklasse, und die Formatierung gut funktioniert
hat wird es mit ``Gut'' bewertet.\\
Le Chat hatte etwas mehr Probleme gemacht. Bei der Risikotabelle war die Formatierung insofern kein Problem, da man die einzelnen 
Spalten einfach in eine eigene Tabelle übernehmen konnte und die Risikoarten selbst dazwischen schreibt. Erst bei der Maßnahmentabelle
hat LeChat Probleme mit der Zuweisung der Attribute bekommen. Daher wird Le Chat mit ``Befriedigend'' bewertet.\\
Gemini hat am meisten Probleme gemacht. Alleine schon die Tatsache, dass Gemini mitten in der Generierung diese als fertig betrachtet 
und dadurch die Tabellen unvollständig erstellt werden, sorgt dafür, dass Gemini für solche Erstellungen eher ungeeignet ist. Die 
anderen Probleme wie die fehlerhafte Formatierung und das die Attribute falsch berechnet und festgelegt werden kommen dabei noch hinzu.
Dies sorgt dafür, dass Gemini hier die Bewertung ``Mangelhaft'' erhält.\\

Wenn man allerdings sich nur die Erstellung von Risiken mit dazugehörigen Maßnahmen anschaut, erhalten alle drei Tools die Bewertung 
``Sehr gut''. Die erstellten Risiken und Maßnahmen waren zwar alle eher welche, die man vermutlich als erstes benennt und auch 
Projekt unabhängig sind, wurden aber dennoch sehr gut erstellt. Auch bei Gemini werden einzelne Risiken mit dazugehörigen Maßnahmen 
in einem rutsch erstellt, weshalb man dieses Problem bei der Erstellung der Risiken und Maßnahmen nicht ankreiden kann.


\section{Anforderungsspezifikation} \index{Anforderungsspezifikation} \label{CompAnforderungsspezifikation}

Für die Anforderungsspezifikation wurde für jeden Inhalt ein eigener Prompt erstellt. Daher wird im folgenden die Erstellung der Einleitung, 
der Systemarchitektur, des Fachliche Datenmodells, des Anwendungsfalldiagramms, der detaillierten Anwendungsfall Beschreibung mit Aktivitätsdiagramm, 
der Benutzungsschnittstelle mit der Dialog Navigation, der detaillierten Ausarbeitung von Dialogen und der nichtfunktionalen Anforderungen einzelnen
Beschrieben und anschließend bewertet.\\

\subsection*{Einleitung}

Für die Einleitung wurde der folgende Prompt verwendet:

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir für die Anforderungsspezifikation eine Einleitung. Diese soll kurz, mit 2-3 Sätzen, in das Dokument einführen. Anschließend soll 
        ein Abschnitt zum "Zweck und Umfang des Dokuments" kommen, welcher eine Beschreibung der Notwendigkeit des Systems für den Kunden sowie eine 
        Kurzbeschreibung der Funktionalität und der Nachbarsysteme beinhaltet. Danach wichtige "Begriffe und Abkürzungen" erklärt werden. Zum Schluss 
        kommt ein Abschnitt "Verweise auf sonstige Ressourcen", wo auf die Spielregeln verwiesen wird.
        \vfill
    \end{tcolorbox}
    \caption{Prompt Einleitung Anforderungsspezifikation}
    \label{Prompt Einleitung Anforderungsspezifikation}
\end{prompt}

Bei der Erstellung des Prompts musste darauf geachtet werden, den Abschnitt ``Zweck und Umfang des Dokuments'' genauer zu beschreiben, da hier ansonsten
die generierte Ausgabe sehr ausschweifend und unspezifisch erstellt werden. Grundsätzlich hat die Erstellung gut geklappt.\\

Bei ChatGPT ist lediglich auffällig, dass beim Abschnitt ``Zweck und Umfang des Dokuments'' nicht der Zweck der Anwendung beschrieben wurde, sondern der Zweck 
des Dokuments. Die Kurzbeschreibung der Funktionalität wurde dafür gut erstellt. Bei der Kurzbeschreibung der Nachbarsysteme wurden die einzelnen Teile 
der Anwendungs erläutert, also das Spielsystem, das Kommunikationsprotokoll für RMI und die Benutzeroberfläche, und keine anderweitigen System, da die 
Anwendungs alleinstehend ist.\\

Die Erstellung der Texte mit Gemini hat sehr gut funktioniert. Auffällig war hier allerdings, dass bei der Beschreibung der Funktionalität des System 
nur die Anforderungen an das Spiel selbst beschrieben wurden. Die auflistung der Anforderungen an die Implementierung wurden hier vernachlässigt.\\

Le Chat hat die Beschreibung gut erstellt. Der einzige Aspekt der auffällig war ist, dass beim Abschnitt ``Verweis auf sonstige Ressourcen'' ein Link 
auf eine Webseite für die Regeln von Mensch ärgere dich nicht eingefügt wird.\\

Bewertet wird ChatGPT mit ``Gut'', da hier der Zweck des Dokuments beschrieben wurde, obwohl im Prompt explizit nach einer Beschreibung der Notwendigkeit
des Systems für den Kunden gefragt wurde.\\
Le Chat und Gemini werden mit ``Sehr gut'' benotet, da hier keine Inhatlichen Fehler vorhanden sind und soweit alles gepasst hat. Die bei Gemini nicht 
aufgelisteten Anforderungen an die Implementierung sind hier nicht tragisch, da diese im Projekthandbuch bereits vermerkt sind und nicht nochmal 
wiederholt werden müssen.

\subsection*{Systemarchitektur}

Die Systemarchitektur wurde mit folgenden Prompt erstellt:

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir für die Anforderungsspezifikation die Systemarchitektur. Diese beinhaltet einen groben Überblick über die erwartete Systemarchitektur 
        und Einordnung des Systems in die Systemlandschaft des Kunden. Falls Schnittstellen zu Nachbarsystemen bestehen, dann müssen diese abgebildet werden.
        \vfill
    \end{tcolorbox}
    \caption{Prompt Systemarchitektur}
    \label{Prompt Systemarchitektur}
\end{prompt}

Auch hier muss beschrieben werden, was genau erstellt werden soll. Wichtig hier ist, dass man in den selben Chat schreibt, in dem man die Dokumente vorher
schon erstellt hat. Dadurch wissen die Tools was zu erstellen ist.\\

Bei ChatGPT wurde sogar ein Diagramm in den Chat ``gezeichnet''. Die Beschreibung und das Diagramm ist jedoch für die Systemarchitektur schon viel zu genau.
Es hätte gereicht den Client, den Server und die Datenbank darzustellen und diese richtig miteinander zu verbinden. Bei der ersten Erstellung wurden 
die Verbindungen zwischen Client und Server und Server und Datenbank unidirektional dargstellt. Nach einer weiteren Eingabe, ob das so gewollt ist, wurde 
dies jedoch korrigiert und die Verbindung wurde bidirektional eingezeichnet.\\

Gemini hatte das gleiche Problem wie ChatGPT, dass hier die Komponenten bereits zu genau beschrieben werden. Die Komponenten ähneln teilweise denen, die bei 
dem Komponentendiagramm erstellt werden müssen, als auch den Klassen aus dem Fachlichen Datenmodell. Desweiteren hat Gemini zunächst keine 
Datenbank miterstellt. Auf Nachfrage, ob eine Datenbank miterstellt werden sollte, wurde zunächst nur erklärt, woran man dies ausmachen kann. 
Erst mit einer expliziten Eingabe, die Datenbank mit hinzu zu fügen, wird dies gemacht. Bei der Beschreibung der Schnittstellen wurde beschrieben, 
dass zwischen Client und Server RMI verwendet wird. Allerdings wird bei der Datenbank nur von der Datenbank-Schnittstelle geschrieben. Daher ist hier 
nicht richitg definiert worden, mit was und wie die Datenbank verbunden ist.\\

Nach der Eingabe kam bei Le Chat eine kurze Textuelle Beschreibung der Client- und Server-Anwendung sowie der Datenbank. Außerdem wurde beschrieben, 
dass Schnittstellen zu Nachbarsystemen ebenfalls mit aufgenommen werden sollen. Diese Beschreibungen haben soweit gut gepasst. Auf nachfrage, wie denn 
dann die Abbildung aussehen soll, wurde beschrieben, dass der Client, der Server und die Datenbank jeweils eigenständige Blöcke sein sollen. Dies ist soweit
richtig. Es wurde jedoch nicht genau Beschrieben wie die Beziehungen zwischen den Komponenten aussehen. Daher wurde nochmal eine Eingabe getätigt, wie denn 
die Beziehung zwischen den Komponenten aussieht. Hier wurde richtig dargestellt, dass der Client und der Server kommunizieren und der Server mit der Datenbank, 
jedoch nicht der Client mit der Datenbank. Die restliche Beschreibung, wie diese Komponenten kommunizieren, ist wieder etwas zu ausführlich. Die Beschreibung 
reicht jedoch, um die Skizze selber zu erstellen, was kein negatives Kriterium ist, da bei den kostenfreien Versionen nicht davon ausgegangen wird, dass diese 
das können.\\

Zusammenfassend lässt sich hier sagen das alle drei Tools die Systemarchitektur etwas zu genau erzeugen. Jedoch lassen sich bei ChatGPT und Le Chat die richtigen Inhalte 
aus der Ausgabe kopieren und die zu detaillierten Beschreibungen können einfach rausgelöscht werden, weshalb die Tools mit der Note ``Gut'' bewertet werden. Geminis Ausgabe
kann allerdins aufgrund der fehlenden Beschreibung, wie die Datenbank mit den anderen Komponenten verbunden ist, nicht einfach kopiert und gekürzt werden. Daher wird Gemini 
hier mit ``Befriedigend'' bewertet.


\subsection*{Fachliches Datenmodell}

Das erste größere und anspruchsvollere Dokument ist das Fachliche Datenmodell. Dieses wurde mit folgendem Prompt erstellt:

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir nun für die Anforderungsspezifikation das Fachliche Datenmodell. Dieses soll mit Hilfe eines UML Klassendiagrammes mit ergänzenden Beschreibungen 
        bzw. EInschränkungen spezifiziert werden. Das Modell soll alle Entitätstypen mit deren Eigenschaften, Beziehungen und Einschränkungen besitzen.
        \vfill
    \end{tcolorbox}
    \caption{Prompt Fachliches Datenmodell}
    \label{Prompt Fachliches Datenmodell}
\end{prompt}

Dabei muss explizit erwähnt werden, dass ein UML-Klassendiagramm gewünscht ist, damit die Aussgabe das richtige Format besitzt. Außerdem sollte erwähnt werden,
dass ergänzende Beschreibungen mit erstellt werden soll, damit diese Vorgabe auch direkt mit erfüllt ist und die Tools ihr Diagramm einmal näher erläutern.\\

Bei ChatGPT war direkt auffällig, dass für jede Klasse eine ID erstellt wurde. Dies führt zum einen dazu, dass die Anwendung sehr Datenbanklastig ist und zum 
anderen ist dies auch einfach bei manchen Klassen nicht nötig. Zum Beispiel beim User könnte man, je nach logIn-Daten, den Namen oder die E-Mail-Adresse 
einzigartig machen und damit den User identifizieren. Des weiteren haben die Beziehungen nicht immer gepasst. Zum Beispiel die 1:1 Beziehung zwischen 
``Spielfigur'' und ``Feld''. Es muss natürlich nicht auf jedem Feld eine Spielfigur stehen sondern auf einem Feld kann (0..1) eine Spielfigur stehen. Dieses Problem
zieht sich auch durch die gesamten Versuche, das Fachliche Datenmodell zu korrigieren. Häufig passiert es auch, dass wenn ein anderer Fehler korrigiert wird, 
eine richtige Beziehung zu etwas falschem geändert wird. Bei der erstellten Skizze waren ebenfalls die Beziehungen falsch eingezeichnet. Außerdem zeigten Beide Pfeile 
zwischen zwei Klassen in die gleiche Richtung. Bei Nachfrage, ob die Beziehung nicht in beide richtungen zeigen sollten, wurde gesagt, dass das stimmt und die 
Beziehungen Bidirektional sein sollten, jedoch wurde an der Zeichnung nichts geändert. Desweiteren ist aufgefallen, dass bei der Klasse ``Feld'' ein Attribut gefehlt
hat, das beschreibt, ob das Feld belegt ist oder nicht. Außerdem wurde in einem String in ``Spiel'' das Spielbrett gespeichert. Auf Nachfrage wie dies Implementiert
werden soll, wurde geantwortet das dies nicht die beste Lösung ist, sondern das Spielbrett dynamisch in der Anwendung generiert und angezeigt werden sollte.
Weitere Probleme hatte ChatGPT mit der Speicherung der Farbe und der Position. Manchmal wurden diese Attribute in ``Spieler'', manchmal in ``Spielfigur'' und teilweise
auch in beiden gespeichert. Damit es später einfacher zu realisieren ist an mehreren Spielen teilnehmen zu können, wurde die Eingabe, dass es mehr Sinn macht den 
``Spieler'' in ``User'' und ``Spieler'' aufzuteilen, getätigt. ChatGPT hat dies dann genau wie beschrieben gemacht. Desweiteren wurde der Würfel vergessen, welcher 
jedoch nach Hinweis diesbezüglich in ``Spiel'' hinzugefügt wurde. Nach der letzten Ausgabe des Fachlichen Datenmodells wurde, nach Aufforderung, ein PlantUML-Diagramm 
erstellt. In diesem wurde an den Assoziationen Leseunterstützung angefügt. Diese Leseunterstützung sind jedoch nur von oben nach unten hilfreich. Zum Beispiel ``Feld 
steht auf Spielfigur'' ist keine Hilfreiche Beschriftung. Des weiteren sind alle Festlegungen der Vielfachheit auf der falschen Seite. Als Beispiel muss an der 
Assoziation zwischen ``Spieler'' und ``Spielfigur'' die ``1'' auf der Seite von ``Spieler'' sein und die ``1..4'' auf der Seite von ``Spielfigur''. Desweiteren würden 
Pfeile an den Assoziationen helfen, die Flussrichtung zu verdeutlichen.\\
Die zu dem Dokument gehörige ergänzende Beschreibungen und Einschränkungen wurden erst auf Nachfrage erstellt, doch ab da an passten diese ganz gut. Auch, dass beim 
Format direkt die Länge der Strings begrenzt wurden, zeigt das ChatGPT hier auch Sicherheitstechnische Aspekte mit einbezieht.\\

Geminis Ausgabe war ähnlich zu der von ChatGPT. Auch hier wurden für alle Klassen eine ID erstellt und es wurden bereits die Referenzen in den Klassen auf andere Klassen
eingefügt. Dies gehört jedoch nicht in das Fachliche Datenmodell. Ebenfalls auffällig ist, dass lediglich die IDs eindeutig sind. Dadurch müsste man sich mit seiner ID
anmelden, da es sonst passieren kann, dass es mehrere ``Spieler'' mit dem gleichen Namen und Passwort gibt. Grundsätzlich ist die Implementierung etwas eigenartig, da jeder 
``Spieler'' einen ``Spielstand'' besitzt. Hier werden allerdings auch allgemeine Informationen wie ein Spielbrett, ein Spielstand und das Datum und die Uhrzeit gespeichert. 
Es würde mehr Sinn machen diese Eigenschaften in ``Spiel'' nur einmal für alle ``Spielstände'' zu speichern. Ebenfalls eher schlecht umgesetzt sind die Beschreibungen 
der Assoziationen zwischen den Klassen. Hier werden entweder ``... zu 1'' oder ``... zu *'' Beziehungen beschrieben und teilweise sind die Assoziationen nur unidirektional 
beschrieben. Desweiteren haben manche Klassen die für das Spiel benötigt werden Assoziationen mit ``Spieler''. Da aber die Spielinformationen eines Spielers über 
``Spielstand'' laufen, benötigt man diese nicht, sondern es reichen Assoziationen mit ``Spielstand''. Dann lässt sich automatisch der dazugehörige ``Spieler'' 
damit verbinden. Andersrum verhält es sich mit der Assoziation ``Nimmt an vielen Spielen teil'' von der Klasse ``Spieler''. Da ``Spieler'' mehrere ``Spielstände'' haben 
kann und diese zu einem ``Spiel'' gehören, ist diese Assoziation unnötigt. Die Eigenschaften haben auch keine, wie bei einem UML-Klassendiagramm üblich, festlegung des 
Typs der Eigenschaften. Als zweite Eingabe wurde angewiesen, die Klasse ``Spieler'' zu einer Klasse ``User'' und einer 
Klasse ``Spieler'' aufzuteilen, um den LogIn-Prozess zu vereinfachen. Da allerdings bereits bei der ersten Eingabe die Klasse ``Spieler'' lediglich die allgemeinen 
Benutzerinformationen umfasst, und die Spielinformationen in den entsprechenden Klassen gespeichert werden, war die Eingabe unnötig, hätte aber trotzdem funktioniert sollen.
Gemini hatte jedoch mit der Umsetzung probleme. Zum einen wurde die Klasse ``Spielfigur'' entfernt und die Klasse ``Spieler'' hat die Eigenschaft ``Position'' erhalten.
Auf Nachfrage, warum die ``Spielfigur'' Klasse entfernt wurde, wurde diese einzeln neu Ausgegeben und nicht in das Fachliche Datenmodell wieder eingebunden. Mit der 
Eingabe, nochmal das gesamte UML-Klassendiagramm auszugeben, wurde die Spielfigur einfach wieder eingesetzt, allerdings hat dann ``Spieler'' aufeinmal eine ``Spielfigur''
und ``Spielstand'' sind ebenfalls nochmal mehrere ``Spielfiguren'' zugeordnet. Ebenfalls gehörte nur noch ein ``Spielstand'' zu einem ``Spiel'' und zu einem ``Spieler''.
Hier wurde also nur noch ein Einzelspieler-Modus implementiert. Auf Nachfrage, ob dies so ist, wurde zugestimmt und mehrere Lösungsvorschläge gemacht und auf einer weiteren
Nachfrage, einen davon in das Diagramm einzubinden, wurde dies geamcht, allerdings sind immernoch zahlreiche Fehler in dem Diagramm vorhanden. Bereits die erste Erstellung 
des Fachlichen Datenmodells und auch die späteren Ausgaben betrachten alle die Anforderung, dass ein Chat im Spiel vorhanden sein soll und das es ein Punktesystem 
geben soll, nicht. Dies ist sehr kritisch, da die nachträgliche Einfügung von Anforderung kosten- und zeitintensiv ist.\\

Auch Le Chat hatte zu beginn nur eine Klasse ``Spieler''. Für eine Anwendung wo ein Spieler an mehreren Spielen teilnehmen sollen kann, macht es jedoch Sinn, diese 
Klasse auf zwei Klassen, ``User'' und ``Player'', aufzuteilen. Desweiteren wurde bei Le Chat, wie es eigentlich in einem UML-Klassendiagramm gehört, die Typen der
Attribute nicht festgelegt. Außerdem ist die Frage, wenn die E-Mail-Adresse eines Spieler eindeutig sein muss, warum dann trotzdem eine eindeutige ID benötigt wird.
Daneben wurde auch die Anforderung des Kunden, das ein Punktesystem eingebunden werden soll, ignoriert, da es kein Attribut zum Speichern der Punktzahl gibt.
Die Bezeichung der Beziehungen zwischen den Klassen ist, in der Textuellen Beschreibung für die Beziehung, eher an einem ER-Modell orientiert und nicht an einem 
UML-Klassendiagramm. Die genaue Bezeichnung für die Vielfachheit muss aus der Beschreibung selbst erstellt werden. Diese war jedoch auch teilweise fehlerhaft. Zum 
Beispiel, dass ein Player an einem oder mehreren Spielen teilnehmen kann, macht kein Sinn, da die Klasse ``Player'' die Eigenschaften eines Spielers
im Spiel beschreibt. Diese kann schlecht in mehreren Spielen gleich sein. Auch einfachere Sachen wie die Zuweisung der Spielfiguren war ein Problem. Zum Beispiel bei 
der Beschreibung der Beziehung zwischen Player und Spielfigur wurde definiert, dass ein Player eine oder mehrere Spielfiguren besitzen kann. Dies entspricht aber nicht 
den normalen Regeln von Mensch ärgere dich nicht, wo jeder Spieler immer genau vier Spielfiguren besitzt. Daneben wurde auch hier der ``Player''-Klasse ein Attribut
für die Position auf dem Spielbrett festgelegt. Nach der Eingabe [Verweis!!!! 05\_03\_LeChat] wurden genau diese Beziehungen richtig geändert, jedoch waren immer noch Fehler enthalten
wie zum Beispiel, dass ein Spiel eine oder mehrere Spielfiguren enthalten kann. Anschließend wurde gefragt ob der Würfel auch in das Fachliche Datenmodell mit aufgenommen
werden sollte, woraufhin sowohl eine eigene Klasse ``Dice'' als auch ein Attribut ``dice: Dice'' in der ``Game''-Klasse erstellt wurde. Anschließend wurde gefragt ob 
das Fachliche Datenmodell in PlantUML erstellt werden kann. Hier fällt besonders auf, dass die Verbindungen zwischen den Klassen alles Kompositionen sind, was aber soweit
auch Sinn ergibt. Außerdem fällt auch auf, dass hier bereits die Primär- und Fremdschlüssel dargestellt werden. Dies ist für das Fachliche Datenmodell allerdings zu spezifisch.
Ein weiterer Fehler ist die Beziehung zwischen ``Game'' und ``Figure''. Hier wird festgelegt, dass ein Spiel aus 16 Figuren besteht. Allerdings gibt es auch ein 
Attribut ``max\_players'' und es wurde bereits festgelegt, dass ein Spiel aus 1..4 Spieler besteht. Daher kann es auch sein, falls nicht immer auf 4 Spieler mit KI-Gegner aufgefüllt 
wird, das weniger als 16 Figuren auf dem Spielfeld sind. Hier lässt sich allerdings eh kritisch hinterfragen ob die Komposition zwischen ``Game'' und ``Figure'' überhaupt 
notwendig ist, da durch die Verbindung zwischen ``Figure'' und ``Player'' und der zwischen ``Game'' und ``Player'' die Figuren sowieso genau einem Spiel zugeordnet sind.\\
Le Chat erstellt das Format und die Beschreibung der Attribute auch erst auf Nachfrage. Jedoch hält sich die Ausgabe in Grenzen. Bei dem Format wird lediglich der Typ der
Attribute beschrieben und es gibt keine Eingrenzung der Größe und der Länge der Werte.\\

Alle drei Tools schaffen es, ein grobes Grundgerüst für das Fachliche Datenmodell zu erstellen. Bei allen drei war dabei auffällig, dass für jede Klasse eine 
eindeutige ID erstellt wurde und auch schon Referenzen in die Klassen eingefügt wurde. Das Hauptproblem bei ChatGPT und Gemini stellt die richtige Darstellung der 
Assoziationen zwischen den Klassen dar. Besonders die Beschreibung der Vielfachheit stellt die beiden Tools vor Schwierigkeiten. Dies funktioniert bei Le Chat etwas besser, 
aber immer noch nicht fehlerfrei. Dafür hatte Le Chat mit mehreren kleineren generellen Problemen zu kämpfen. Es ist außerdem auffällig das ab einem gewissen 
Punkt, die Erstellung des Prompts und das analysieren der neuen Antwort länger dauert als die Fehler selbstständig anzupassen. Daher ist es nicht allzu schlimm 
wenn ein Attribut irgendwo doppelt vorkommt oder eine Assoziation falsch beschriftet ist. Deshalb und aufgrund der Komplexität dieses Diagrammes erhalten 
sowohl ChatGPT und Le Chat die bewertung ``Gut''. Das Grundgerüst kann hier ohne Probleme übernommen werden und anschließend an die eigenen Bedürfnisse 
und Anforderungen angepasst werden. Gemini erhält aufgrund der nicht betrachtung der Anforderungen die Note ``Ausreichend''.


\subsection*{Anwendungsfalldiagramm}

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir nun für die Anforderungsspezifikation ein Anwendungsfalldiagramm. Dieses soll alle Anwendungsfälle beinhalten und den Rollen zuweisen, die für die 
        Applikation benötigt werden.
        \vfill
    \end{tcolorbox}
    \caption{Prompt Anwendungsfalldiagramm}
    \label{Prompt Anwendungsfalldiagramm}
\end{prompt}

Mit diesem Prompt wurde das Anwendungsfalldiagramm erstellt. Der Prompt ist sehr einfach gehalten und beschreibt lediglich kurz den Inhalt des Diagrammes.\\

ChatGPTs erste Ausgabe enthielt zwei Rollen, den ``Spieler'' und den ``User''. Der ``User'' hatte den Anwendungsfall ``Spiel erstellen''. Dadurch kamm die 
Frage auf, ob man als Spielersteller besondere Rechte haben sollte. ChatGPT hat darauf hin die neue Rolle ``Gastgeber'' hinzugefügt. Fraglich ist allerdings
die Einzeichnung in das PlantUML-Diagramm. Dem zufolge erbt der ``Gastgeber'' von ``Spieler'' und dieser von ``User''. Das ist allerdings nur Teilweise richtig.
Der ``Gastgeber'' muss von ``Spieler'' erben, da auch der ``Gastgeber'' die zum Spielen benötigten Anwendungsfälle benötigt. Allerdings sollte ``Spieler'' nicht 
von ``User'' erben, da die Anwendungsfälle auf die der ``User'' zugreifen kann, während eines Spiels nicht benötigt werden. Des weiteren hatte ``Spieler'' die 
Anwendungsfälle ``Zug machen'' und ``Spielfigur bewegen''. Dadurch war zunächst unklar welche Tätigkeiten ``Zug machen'' beinhaltet. Auf Nachfrage antwortete 
ChatGPT allerdings, dass zu ``Zug machen'' alle Tätigkeiten beinhaltet, die man während einem Zug durchführen muss (Würfeln, Auswählen und Bewegen der Spielfigur, 
Schlagen gegnerischer Figuren und Beenden des Zuges). Daher ist der Anwendungsfall ``Spielfigur bewegen'' unnötig. Auf einen Hinweis diesbezüglich entfernt ChatGPT 
den Anwendungsfall aus dem Diagramm. Zuletzt konnte der Anwendungsfall ``Chat nutzen'' mit der Rolle ``User'' durchgeführt werden. Dies entspricht allerdings nicht 
den Anforderungen, da nur während eines Spiels ein Chat vorhanden sein soll. Auch hier wird der Anwendungsfall nach einem Hinweis von ChatGPT wieder entfernt. 
Grundsätzlich wurde das Anwendungsfalldiagramm so passen, allerdings muss man sich die Frage stellen, ob man noch eine Rolle für Administrative Zwecke benötigt, 
welcher direkt Daten, wie zum Beispiel User, aus der Datenbank löschen und hinzufügen kann. Positiv herausheben sollte man, dass ChatGPT bei jeder Ausgabe 
automatisch Code für ein Diagramm bei PlantUML erzeugt hat.\\

Das Anwendungsfalldiagramm von Gemini erstellt bei der ersten Ausgabe lediglich Anwendungsfälle die zum Spielen benötigt werden. Die Rolle ``Spielverwaltung'' 
beschreibt dabei die Aufgaben die auf dem Server passieren. Die Rollen ``Spieler'' und ``Spielverwaltung'' sind laut Gemini miteinander verwoben. 
Die Rolle ``Spieler'' beschreibt dabei, was der Spieler auf der Client-Seite macht. Die Rolle ``Spielverwaltung'' beschreibt was anschließend auf der 
Server-Seite passiert. Dies ist allerdings nicht das, was ein Anwendungsfalldiagramm darstellen soll. Daher wurde mit derselben Eingabe eine neue Antwort 
generiert. Hier fällt zum einen auf, dass die Rolle ``Gast'', obwohl in der Beschreibung der Rolle definiert wird, dass diese zum Beispiel keine Spiele 
spielen kann, den Anwendungsfall ``Spiel suchen'' und ``Spiel beitreten'' durchführen kann. Zumanderen kann die Rolle ``Spieler'' sowohl generelle 
Benutzerinteraktionen durchführen, als auch Spielaktionen. Es macht Sinn dies voneinander zu trennen, was Gemini auch richtig macht. Ein weiterer 
negativer Punkt ist der Anwendungsfall ``Benutzer verwalten'' vom ``Administrator''. Dieser Anwendungsfall ist zu grob definiert und sollte in die 
einzelne Anwendungsfälle, also ``Benutzer erstellen''. ``Benutzer bearbeiten'' und ``Benutzer löschen'' unterteilt werden. Auch Gemini erstellt für 
die Aktionen im Spiel einen großen Anwendungfall ``Spiel spielen'', wo Gewürfelt wird, die Spielfigur bewegt wird und Spielaktionen ausgeführt werden.
Negativ fällt außerdem auf, dass auch hier die Anforderungen, das es ein Chat und ein Punktesystem geben soll, nicht eingebunden wurden.\\

Eine erste Ausgabe mit direkt vier Rollen erstellt dahingegen Le Chat. Hier wird eine eigene Rolle ``Gast'' erstellt, welche ein Benutzer erhält der noch nicht eingeloggt ist, und 
es wird direkt ein Rolle ``Admin'' mit angegeben. Ein unterschied zu [ChatGPT] ist hier, dass wenn ein Spieler am Zug ist, jede Aktion ein eigener Anwendungsfall
ist. Dabei ist zu beachten, dass ``Figur setzen'' und ``Figur schlagen'' nicht getrennt werden dürfen, da diese Aktionen zusammengehören. Wenn eine Figur gesetzt 
wird muss automatisch überprüft werden ob sich auf dem Feld bereits eine Figur befindet, wenn ja muss diese automatich geschlagen werden. Außerdem sind die 
Anwendungsfälle ``Benutzer verwalten'' und ``Profil bearbeiten'' zu ungenau definiert. Hier muss man für jede Aktion einen eigenen Anwendungsfall erstellen. Diese beiden Punkte wurden 
Le Chat als Eingabe gegeben und anschließend anständig korriegiert. Auf Nachfrage wurde hier auch Code für ein PlantUML-Diagramm erzeugt. Dieses ist jedoch sehr
unübersichtlich, da für jeden Anwendungsfall ein ``Männchen'' erstellt wird und diese einfach untereinander aufgelistet werden. Die Versuche, ihn davon wegzubringen 
und das Diagramm ähnlich wie ChatGPT zu erstellen waren alle vergebens.\\

Zusammenfassend lässt sich sagen, dass alle drei Tools das Anwendungsfalldiagramm schon ganz gut beschreiben. Ein paar Ungenauigkeiten gibt es dennoch und aus 
diesem Grund werden sowohl ChatGPT als auch Le Chat mit ``Gut'' bewertet. Dass Le Chat das PlantUML-Diagramm nicht übersichtlich erstellen kann fließt hier nicht
negativ in die Bewertung mit ein, da dass erstellen des Diagramms keine Anforderung war sondern es reicht wenn die Diagramme anständig beschrieben werden, so das man 
diese selbst erstellen kann. Dies ist bei der Beschreibung von Le Chat gegegeben. Gemini hingegen wird auch hier nur mit ``Ausreichend'' benotet, da die Anforderungen 
nicht alle umgesetzt werden und dies ein sehr wichtiger Punkt bei der Erstellung der Anforderungsspezifikation ist. Nachträglich eingefügte Anforderungen sind kosten- 
und zeitintensiv und sollten unbedingt vermieden werden. Vorallem weil Sie einfach vergessen werden. 

\subsection*{Anwendungsfälle}

Nun geht es um die Erstellung der detaillierten Beschreibung für die einzelnen Anwendungsfälle. Dazu wurden zwei Anwendungsfälle ausgesucht.
Einmal ``Anmelden'' als leichteren Anwendungsfall und ``Zug machen'' [ChatGPT] bzw. ``Figur setzen oder schlagen'' [Le Chat] 
als komplexeren Anwendungsfall. Dazu wurde mit zwei Prompts gearbeitet. Für den Anwendungsfall ``Anmelden'' wurde folgende Eingabe benutzt:

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir nun für die Anforderungsspezifikation, basierend auf dem Anwendungsfalldiagramm, eine detaillierte Beschreibung für den Anwendungsfall „Anmelden“. Dabei 
        soll zunächst der Anwendungsfall in einem Satz beschrieben werden, was dieser macht. Anschließend soll der Akteur, der Auslöser, die Vorbedingung und die Häufigkeit 
        beschrieben werden. Danach soll ein Aktivitätsdiagramm erstellt werden. Dabei werden die Aktivitäten dem Client oder dem Server zugewiesen, wo diese bearbeitet werden. 
        In dem Diagramm sollen keine Dialog beschreibung, wie Fenster mit Fehlermeldung anzeigen, beschrieben werden. Es sollen lediglich Dienste beschrieben werden, die der 
        Server anbietet. Zuletzt werden die Aktivitäten aus dem Diagramm kurz beschrieben.
        \vfill
    \end{tcolorbox}
    \caption{Prompt AF Anmelden}
    \label{Prompt AF Anmelden}
\end{prompt}

Der Prompt beschreibt die Struktur des Dokuments mit den Inhalten. Außerdem wird der Aufbau des Aktivitätsdiagramms beschrieben und das keine Dialog Beschreibungen 
in das Diagramm gehören. Einige Sachen werden hier direkt ganz gut erstellt. Auffällig ist, dass bei der ``Häufigkeit'' keine grobe Schätzung angegeben wird sondern 
Aussagen wie ``Jedes Mal, wenn der Benutzer die Anwendung nutzen möchte.''. Dies ist keine Sinnvolle Beschreibung der Häufigkeit.\\

Die erste Ausgabe wurde mit ChatGPT-4o erstellt. Dabei ist vorallem aufgefallen, dass die Beschreibung nicht zu dem PlantUML-Diagramm passt. Die Aktivitäten
sind anders benannt und auch die Anzahl der Aktivitäten simmt nicht überein. Außerdem wird sowohl in der Beschreibung als auch in dem Diagramm bereits 
viel zu genau beschrieben was passiert. Zum Beispiel die Aktivität ``Session erstellen'' ist für die Beschreibung eines Anwendungsfalls viel zu genau.
Dies beschreibt bereits ``Wie'' der Anwendungsfall umgesetzt wird und gehört somit in das Architekturdokument. Aufgrund, dass 4o hier zuviel erstellt hat, 
wurde die Nachricht mit ChatGPT-3.5 nochmal generiert. Man sieht schonmal direkt, dass deutlich weniger Aktivitäten und keine Beschreibung der Implementierung 
erstellt wurden. Die Aktivitäten passen zum Anwendungsfall und beschreiben diesen gut. Wenn man jedoch die Diagramme von 4o und von 3.5 vergleicht,
fallen einem einige Fehler auf, die beide machen. Zum einen wird die Aktivtät, die überprüft wird, in den Entscheidungsknoten reingeschrieben. Diese muss jedoch als eigene 
Aktivität oben drüber stehen. Des weiteren sollten die Beschriftungen an den Pfeilen des Entscheidungsknoten in eckige Klammern. Auch das die Pfade, die 
aus dem Entscheidungsknoten entstehen, wieder zusammenführen, ist falsch. Bei dem Diagramm der 3.5er Version fehlt außerdem der Start- und Endknoten und auch 
bei der 4o Version sollten zwei Endknoten vorhanden sein. Einmal für ``Anmeldung fehlgeschlagen'' und einmal für ``Anmeldung erfolgreich'' [01\&02 GPT Anmelden].
Wenn man die 3.5er Version auf diese Hinweise allgemein Hinweist [siehe 2. Prompt 03 GPT Anmelden] führen zwar die beiden Pfade nach dem Entscheidungsknoten nicht mehr 
zusammen, jedoch endet der eine ohne Endknoten und im Entscheidungsknoten steht immernoch die Aktivität. Wenn man ihm genau sagt, was er mit welcher Aktivität
machen soll, wird das Aktivitätsdiagramm komplett Fehlerhaft mit unterbrochenen Verbindungen und einer alleinestehenden Aktivität erstellt.\\
Gibt man den groben Hinweis der 4o-Version [05 GPT Anmelden] setzt dieser die Vorgaben richtig um. Ledliglich die Dialog Interaktion ``Benutzer klickt auf ``Anmelden''''
ist noch vorhanden, welche jedoch nach einem Hinweis auch entfernt wird [06 GPT Anmelden]. Die letzten Kleinigkeiten die noch auffallen sind zum einen, dass
im Entscheidungsknoten nur ``ja'' steht. Hier ist die Frage ob man in PlantUML einen leeren Entscheidungsknoten ohne Text erstellen kann. Ähnlich 
verhält es sich an den Endknoten. Diese können vermutlich auch nicht beschriftet werden, weshalb direkt davor noch Aktivitäten mit der Beschreibung erstellt
werden.\\

Der von Gemini erstelle Anwendungsfall weißt ebenfalls einige Probleme auf. Zum einen definiert Gemini folgende Vorbedingung: Die Anmeldeinformationen des 
Users (Benutzername und Passwort) müssen korrekt sein. Dies ist jedoch nicht richtig, da man auch ohne Konto oder mit falschen Daten versuchen kann sich 
anzumelden. Dazu ist auch die Anmeldung mit dem Benutzername und Passwort nicht richtig, da keines dieser Attribute im Fachlichen Datenmodell als einzigartig
definiert worden sind. Dadurch kann man mit diesen beiden Daten nicht eundeutig einen Benutzer identifizieren. Die einzelnen Aktivitäten passen soweit, 
lediglich die Aktivität ``Sende Anmeldebestätigung'' und ``Speichere Anmeldesitzung'' sind etwas zu genau für die Anwendungsfallbeschreibung. Zu der ersten 
Ausgabe wird auch ein Mermaid-Code generiert, welcher allerdings zu einem Syntax Fehler führt. Daher wurde gesagt, dass doch ein PlantUML-Code für das 
Aktivitätsdiagramm erstellt werden soll. Dies wurde auch gemacht, allerdings zeigte war das Aktivitätsdiagramm in Form eines Sequenzdiagrammes. Dazu wurde 
geschrieben, dass der PlantUML Code folgendes Bild beschreibt, wo dann auf ein Link zu einem Aktivitätsdiagramm aus dem Internet verlinkt wurde. Dieses hat 
jedoch nicht zu dem PlantUML Code gepasst. Es ist zwar ein UML-Aktivitätsdiagramm für ein Anmeldeprozess, allerdings ist dieses nicht in dem Format wie es 
sein soll und außerdem entspricht es auch nicht der vorherigen Beschreibung von Gemini.\\

Le Chat erstellt wieder nur auf Nachfrage ein PlantUML-Diagramm, welches vom Format her auch nicht ganz passend ist, da hier Client und Server übereinander 
stehen und nicht nebeneinander. Außerdem gibt es hier die selben Probleme wie bei ChatGPT, dass im Entscheidungsknoten die Aktivität steht und die Pfade 
danach wieder zusammengeführt werden. Die Textuelle Beschreibung von der ersten Ausgabe [01 Le Chat Anmelden] ist ganz gut und man könnte daraus, mit 
einbisschen mitdenken, ein richtiges Aktivitätsdiagramm erstellen. Bei der zweiten Ausgabe, die mit der selben Eingabe erstellt worden ist, fällt auf 
das trotz des Hinweises, dass keine Dialog Eigenschaften beschrieben werden sollen, die erste Aktivität ``Anmeldeformular anzeigen'' genau das tut.\\

Der Anwendungsfall ``Zug machen'' oder ``Spielfigur setzen oder schlagen'' wurde direkt nach dem Anwendungsfall ``Anmelden'' erstellt. Dadurch wurde
beim Prompt die Beschreibung, was erstellt wurde weggelassen. Stattdessen wurde beschrieben, dass wenn in einer Aktivität ein Wert gespeichert werden
soll, auf den Wert im Fachliche Datenmodell referenziert werden muss. Außerdem wurde der Name des Anwendungsfalls bei den Tools entsprechend angepasst. 
Für ChatGPT sieht der Prompt zum Beispiel wie folgt aus:

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir nun eine detaillierte Beschreibung für den Anwendungsfall "Zug machen". Wenn bei einer Aktivität ein Wert gespeichert wird, sollte 
        in der Beschreibung der Aktivität beschrieben werden, um welchen Wert es sich aus dem Fachlichen Datenmodell handelt. Als Beispiel sollte der 
        gewürfelte Wert in Spiel.wuerfel gespeichert werden.
        \vfill
    \end{tcolorbox}
    \caption{Prompt AF Zug machen}
    \label{Prompt AF Zug Machen}
\end{prompt}

Die Aussgabe von ChatGPT scheint zunächst sehr überwaltigend, doch beim nähreren betrachten ist diese eigentlich schon ziemlich gut. Das Format des PlantUML-Diagrammes
zeigt die selben Fehler auf wie bereits beim Anwendungsfall ``Anmelden'', lassen sich aber alle korrigieren. Eine Aktivität die etwas erschrenkend klingt ist Aktivität 6 
``Berechne möglichen Züge''. Grundsätzlich ist dies nicht grade eine effiziente herangehensweise, was bei einem Mensch ärgere dich nicht Spiel allerdings nicht ganz so
schlimm ist, da sich hier die möglichen Züge auf maximal vier beschränkt. Es fällt auch auf, dass das Würfeln auf Server-Seite stattfindet. Dies ist ansich kein gutes 
Spielerlebnis, wenn man als Spieler nicht würfelt. Das 
Würfeln sollte am besten ein eigener Anwendungsfall sein, da das Würfelergebnis wieder auf Client-Seite gebracht werden muss und dies innerhalb eines Anwendungsfalls
schwierig zu implementieren ist. Auch die Verweise auf das Fachliche Datenmodell halten sich mit zwei Verweisen in grenzen und die Klasse ``Spielzug'' wird überhaupt nicht
betrachtet. Als Hilfe wurde daher nochmal eine Eingabe, mit dem Fachliche Datenmodell [12 GPT FDM] und der Anweisung sich dieses zu merken, erstellt. Anschließend wurde 
der \autoref{Prompt AF Zug Machen} erneut eingegeben. Diese Ausgabe schafft es etwas besser die Verweise auf das Fachliche Datenmodell zu beschreiben. Lediglich ``Spiel.status''
und ``Feld.belegt'' werden nicht erwähnt. Das Würfeln wird auf die ``Client''-Seite geschoben. Jedoch ist dieser Ablauf, wie bereits beschrieben, 
schwierig zu Implementieren und man sollte Würfeln als eigenen Anwendungsfall beschreiben. Es entfällt auch die Aktivität die Überprüft, ob ein Spieler an der Reihe ist. 
Ebenfalls negativ ist, dass die ``Client''-Seite im Aktivitätsdiagramm zu ``Spieler'' 
umbenannt wurde. Dies wird jedoch nach einem Hinweis wieder zurück geändert. Ein Fehler ist auch, dass die Position der Spielfigur zweimal gespeichert wird. Einmal in Aktivität 7
und einmal in Aktivität 9 [04 GPT Zug machen]. Was nach einem Hinweis aber auch korrigiert wird.\\ % Grunsätzlich wird die Beschreibung des Anwendungsfalls aber gut erstellt.
% Man erhält ein Überblick über die nötigen Aktivitäten und den Ablauf des Anwendungsfalls, muss aber einige Fehler selbst aussbessern, da auch hier recht schnell der Punkt 
% erreicht ist, wo die Erstellung der Prompts länger dauert als 

Da das zueletzt erstelle Fachliche Datenmodell voller Fehler war und nicht verwendet werden kann, wurde hier die Frage nach den Verweisen aufs Fachliche Datenmodell 
weggelassen. Die erste Ausgabe konnte scheinbar mit dem Anwendungsfall ``Spiel spielen'' nichts anfangen und wusste nicht so richtig was dieser laut dem 
Anwendungsfalldiagramm beinhaltet. Hier wurden Aktivitäten wie ``Wähle Spieltyp und Spieloptionen:'' erstellt, wo zum Beispiel gewählt wird ob Einzelspieler 
oder Mehrspieler gespielt werden soll. Daher wurde die Eingabe nochmal gemacht, mit dem Zusatz, dass die Beschreibung des Anwendungsfalls aus dem Anwendungsfalldiagramm
mit in den Prompt eingefügt wurde. In der Ausgabe werden Aktivitäten wie ``Wähle Aktion:'' und ``Verarbeite Aktion:'' beschrieben. Dieses Aktivitätsdiagramm beschreibt 
keinen genauen Ablauf sondern beschreibt grob was allgemein passiert. Dies ist allerdings für die Beschreibung eines Anwendungsfalls falsch. Was man hier allerdings Positiv
anmerken muss ist, dass überprüft wird ob das Spiel beendet ist oder nicht. Dennoch wurde auch hier nochmal eine neue Antwort generiert mit dem gleichen Prompt. Diese 
beschreibt auch anständig den Ablauf des Zuges im Aktivitätsdiagramm. Dennoch ist auch hier das Problem, dass der Spieler erst Würfelt, das Ergebniss an den Server geschickt 
wird und der Spieler anschließend eine Spielfigur auswählt. Dies ist in der Implementierung schwer umzusetzten weshalb das Wüfeln als eigener Anwendungsfall betrachtet werden 
sollte. Ebenfalls negativ fällt auf, dass hier nicht mehr geprüft wird, ob das Spiel beendet ist, wie bei der vorherigen Antwort.\\

Bei Le Chat war zu beginn die Beschreibung etwas kurz und es gab auch, außer ``Spiel.wuerfel'' was explizit im Prompt genannt wurde, keine Referenz aufs Fachliche Datenmodell.
Erst nach der nächsten Eingabe [LeChat 02 ZugMachen] wurden die Beschreibungen etwas ausführlicher und es gab Referenzen aufs Fachliche Datenmodell. Diese Referenzen waren 
jedoch falsch und entsprachen nicht dem zuvor erstellten Fachlichen Datenmodell. Hier wurde nämlich häufig auf die Position der Figuren und der Felder über ``.x'' und ``.y''
Werte zugegriffen. Grundsätzlich ist das natürlich eine gute Art und Weise, die Position leichter zu definieren. Jedoch wurde im Fachlichen Datenmodell über einfache Int-Werte
gespeichert. Außerdem ist die Beschreibung der Aktivitäten nicht entsprechend der Regeln von Mensch ärgere dich nicht. In der Aktivität ``Figur setzen oder schlagen'' wird 
beschrieben, dass eine geschlagene Figur aus der Liste der Figuren des Spielers entfern wird. Dies ist natürlich nicht richtig, sondern die Figur sollte einfach auf ein Startfeld 
der entsprechenden Farbe bzw. des entsrpechenden Spielers gesetzt werden. Außerdem wurde Würfeln als eine Aktivität hier aufgeführt. Im Anwendungsfalldiagramm wurde allerdings
für Würfeln ein eigener Anwendungsfall erstellt, weshalb die Aktivität hier unnötig und falsch ist. Nach einem Hinweis diesbezüglich, hat Le Chat ausgegeben, dass das stimmt und
die Aktivität entfernt werden muss. Anschließend wurde, auf Nachfrage, eine Beschreibung des Aktivitätsdiagramms erstellt. Dabei wurde einmal die Aktivität ``Figur setzen oder 
schlagen'' in zwei Aktivitäten aufgeteilt. Einmal ``Figur setzen'' und ``Figur schlagen'' wobei mit einem Entscheidungsknoten entschieden wird, in welche Aktivität gegangen wird.
Die Beschreibung der Flusslinien ist sehr sporadisch und sagt sogar eigentlich aus, dass die erst die Aktivitäten miteinander verbunden sind und diese dann erst mit den 
Entscheidungsknoten und den Endpunkten verbunden werden. Dies sollte aber nicht so sein, da die Entscheidungsknoten ja zwischen den Aktivitäten stehen müssen. Dazu wird beschrieben, 
dass es zwei Endpunkte gibt. Für den Fall, dass erfolgreich die Figur gesetzt oder geschlagen wird und das Verweigern des Zugs. Ebenfalls negativ auffällig ist, dass bei den ersten
beiden Aktivitäten ``Figur auswählen'' und ``Zielfeld auswählen'', jeweils die Information an den Server übermittelt wird. Besser und einfacher wäre es aber, die Infos zusammen in einem
Zug an den Server zusenden. Damit würde es reichen eine Funktion zu erstellen und an den Server zu senden. Der ``Trick'', das zuletzt erstellte Fachliche Datenmodell als Eingabe 
zu nutzen, hat nicht wie bei ChatGPT funktioniert. Wenn man Le Chat nach dem aktuellen Fachlichen Datenmodell fragt, auf welches er sich referenziert, wird auch ein völlig anderes
Datenmodell ausgegeben [LeChat 05 ZugMachenFDM].\\

Fazit[[[[[[[[[[]]]]]]]]]]

\section*{Benutzungsschnittstelle}

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir nun für die Anforderungsspezifikation die Benutzungsschnittstelle. Diese zeigt, von welchem Dialog aus man zu anderen 
        navigieren kann. Es sollen alle Dialoge enthalten sein, mit all deren Verbindungen zueinander.
        \vfill
    \end{tcolorbox}
    \caption{Prompt Benutzungsschnittstelle}
    \label{Prompt Benutzungsschnittstelle}
\end{prompt}

Mit diesem Prompt wird die Benutzungsschnittstelle beschrieben die zeigt, wie man zwischen den Dialogen navigieren kann.\\

Bei ChatGPT wurde zwei mal die Eingabe getätigt.\\
Die erste Eingabe hat im Chat ein ``gezeichnetes'' Diagramm enthalten. Dort waren jedoch sowohl die Verbindungen zwischen Dialogen als auch 
die Einzeichnung der Navigation etwas schwierig, da hier nur in eine Richtung navigiert wird. Außerdem passte dieses auch nicht richtig zu 
der textuellen Beschreibung die mit generiert wurde. Bei der Beschreibung ist aufgefallen, dass ein ``Passwort-zurücksetzen-Dialog'' enthalten 
ist. Allerdings ist in dem Anwendungsfalldiagramm kein Anwendungsfall für das Passwort zurücksetzen erstellt worden, weshalb man entweder 
den Dialog aus dem Diagramm löscht oder den Anwendungsfall ``Passwort zurücksetzen'' nachträglich erstellen muss. Ähnlich verhält es sich mit 
den Anwendungsfällen ``Punkte anzeigen'' und dem Dialog ``Anzeige der Spieler-Liste''. Außerdem ist Fraglich 
ob ein noch nicht angemeldeter Nutzer die Buttons ``Spiel erstellen'' und ``Spiel beitreten'' sehen soll. Hier wäre es angebrachter einen 
eigenen Dialog für nicht-angemeldete Nutzer zu erstellen und zusätzlich ein Hauptmenü.\\
Nach der zweiten Eingabe erhielt man ebenfalls eine textuelle Beschreibung von welchem Dialog man wohin navigieren kann, einen PlantUML-Code
für ein UML-Diagramm sowie eine Beschreibung der Dialoge. Das PlantUML-Diagramm hatte zunächst einen Syntax Fehler, welcher jedoch nach einem 
Hinweis korrigiert wurde. Jedoch ist das Diagramm recht unübersichtlich, da zum einen die Pfiele nur in eine Richtung zeigen und zum anderen
die Struktur etwas durcheinander ist. Die Beschreibung ist dafür abgesehen von einem Punkt sehr gut. Wenn man einem Spiel beigetreten oder 
ein Spiel gestartet hat gelangt man zu dem Dialog ``Spielbildschirm''. Wenn man dort direkt das Spielfeld sieht, was bei einem Hauptbilschirm
während des Spiels wohl der Fall ist, muss man den Anwendungsfall ``Spiel anzeigen'' aus dem Anwendungsfalldiagramm wieder entfernen.\\

Gemini[[[[[[]]]]]]\\
    - Spieltypen? Soll doch normales MÄDN sein
    - Beschreibt den Inhalt der einzelnen Dialoge, zuviel hier
    - Startbildschirm nach öffnen der Anwendung nicht beschrieben -> Wird noch genauer beschrieben als die anderen Dialoge
    - Dialoge und Anwendungsfälle stimmen nicht überein. z.B.: Passwort vergessen, Pausieren des Spiels

Le Chat hat bei der Erstellung der Benutzungsschnittstelle probiert, diese in die Ausgabe mit zu ``Zeichnen''. Die Abbildung war jedoch 
völlig durcheinander und unübersichtlich. Die Verbindung zwischen den Dialogen ist unverständlich und ergeben keinen Sinn. Auch mit Eingaben, 
das die Verbindung doch überarbeitet werden soll, wurde dies nicht besser. Dafür kann man sagen, dass die erstellen Dialoge soweit zu den 
Anwendungsfällen passen und die meisten enthalten sind. Jedoch sind auch einige Dialoge erstellt worden, für die man eigentlich keinen eigenen
Dialog erstellen muss. Zum Beispiel ``Spiel verlassen''. Da würde ein Button reichen, mit dem man zurück zum Hauptmenü gelangt. Auch die 
Textuelle Beschreibung ist nicht vollständig. Bei der Beschreibung des Verlaufes werden Anwendungsfälle, wie zum Beispiel ``Registrieren'' vergessen.
Außerdem stellt sich die Frage, was man beim ``Spiel beitreten'' Dialog sieht. In dem Anwendungsfalldiagramm wurden die Anwendungsfälle ``Spiel suchen'' 
und ``Spiel beitreten'' erstellt. Daher ist etwas ungenau ob die Anwendungsfälle über den selben Dialog gehen oder ob einer der Anwendungsfälle unnötig 
ist. Dies sollte bei einer nähreren Betrachtung der Anwendungsfälle festgelegt werden. Bei der Beschreibung fehlt auch, wie der Admin zu seinen 
Verfügbaren Dialogen navigieren kann.


\subsection*{Dialog}

Für die Erstellung der Dialoge wurden ebenfalls zwei recht einfache Prompts verwendet, die lediglich beschreiben, wie das Dokument 
aufgebaut sein soll. Einmal für den Anwendungsfall ``Anmelden'' und einmal für den Dialog ``Spielbildschirm'':

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir nun für die Anforderungsspezifikation einen passenden Dialog für den Anwendungsfall „Anmelden“. Dabei wird zunächst 
        beschrieben, wann der Dialog geöffnet wird und wozu er dient. Anschließend folgt eine Skizze des Dialoges. Zuletzt werden die 
        einzelnen Elemente des Dialogs beschrieben und definiert, was dort eingetragen wird bzw. was beim drücken passiert.
        \vfill
    \end{tcolorbox}
    \caption{Prompt Dialog Anmelden}
    \label{Prompt Dialog Anmelden}
\end{prompt}

ChatGPT hat in der Ausgabe wieder eine ``gezeichnete'' Skizze erstellt. Bei der ersten Ausgabe für den ``Anmelden'' Anwendungsfall wurde
noch ein Button für ``Passwort vergessen?'' erstellt. Ansich macht dies natürlich Sinn hier einzufügen, allerdings wurde im Anwendungsfalldiagramm
kein Anwendungsfall dafür erstellt. Positiv auffällig ist, dass die erste Ausgabe [GPT 01 Anmelden] in dem Chat erstellt wurde, wo GPT-3.5 
den Anwendungsfall ``Anmelden'' erstellt hat und dort festgelegt hat, dass sich der User mit einem Benutzernamen und einem Passwort anmeldet [GPT 01 Anmelden]
und die zweite Ausgabe [GPT 02 Anmelden] in dem Chat erstellt wurde, wo GPT-4o sich vorher beim Anwendungsfall für eine Email und ein Passwort 
entschieden hat. Bemängeln kann man dabei, dass bei der Beschreibung der Elemente nicht auf das Fachliche Datenmodell verwiesen wurde. Nach einer 
groben Eingabe, dass doch auf die Werte aus dem Fachlichen Datenmodell referenziert werden soll, wurde dies dann auch richtig gemacht. [GPT 03 Anmelden].\\
Bei der Erstellung des Dialogs ``Spielbildschirm'' wurde auch wieder eine textuelle Beschreibung und eine Skizze erstellt. Die Skizze umfasst
allerdings nur einen Vermerk in eckigen Klammern, wo das Spielbrett graphisch dargestellt werden soll. Außerdem wurde auch hier nochmal die Eingabe 
gemacht, dass auf das Fachliche Datenmodell referenziert werden soll. Interessant ist, dass ein extra Button fürs Würfeln erstellt wurde und einer um 
einen Zug zumachen. Bei dieser Implementierung ist es nahelegender, dass für beide Button ein eigener Anwendungsfall gestartet wird. Bei Nachfrage, zu 
beschreiben, wenn ein Anwendungsfall gestartet wird, gibt ChatGPT aus, dass Würfel ein eigener Anwendungsfall ist. Die Restlichen Verweise auf das 
Fachliche Datenmodell und beschreibung welcher Anwendungsfall gestartet wird passen soweit.\\

- Gemini:
    - Beschreibt Anwendungsfall?
    - Schreibt Verweise auf andere Anwendungsfälle oder Dialoge, allerdings eher ungenau
    - Soll geöffnet werden wenn sich der Spieler abmelden möchte?

    - Auch hier wird Anwendungsfall nochmal beschrieben
    - Möglichen Züge werden angezeigt, da aber im Anwendungsfall nicht beschrieben wird, dass die möglichen Züge vom Server an den Client
    geschickt werden, müsste wohl eine Spiel-Logik-Komponente auf der Client-Seite vorhanden sein.

Beim ``Anmelden''-Dialog hat Le Chat wieder nur eine Textuelle Beschreibung erstellt. Diese ist soweit passend. Fürs Anmelden hat sich Le Chat auf die 
Email-Adresse und ein Passwort festgelegt. Im Fachlichen Datenmodell wurde allerdings nur gesagt, dass die ID eindeutig ist, das heißt das entweder 
die Email-Adresse ebenfalls eindeutig gemacht werden muss oder sich diese nicht eignet fürs Anmelden. Ansonsten könnten zwei Benutzer mit derselben
Email-Adresse und dem selben Passwort nicht unterschieden werden. Außerdem fehlt ein Button um zum ``Registrieren''-Dialog zukommen, welcher zumindest
laut dem Anwendungsfalldiagramm vorhanden sein sollte. Passen würde es jedoch zur Benutzungsschnittstelle, da hier kein Dialog fürs Registrieren
eingebunden wurde.\\
Bei der Beschreibung des Dialogs ``Spielbrett'' werden die Inhalte gut beschrieben. Es fehlt lediglich ein Button oder ähnliches um den Spielstand 
anzuzeigen. Dies ist laut dem Anwendungsfalldiagramm ein eigener Anwendungsfall, wobei jedoch die Frage ist, was dieser beschreiben soll oder ob dieser
durch das dauerhafte anzeigen des Spielbrettes hinfällig geworden ist. Bei Nachfrage, ob Le Chat beschreiben kann wann ein Anwendungsfall gestartet wird,
gibt dieser eine zu dem Dialog passende Beschreibung aus. Auch hier fehlen allerdings die Anwendungsfälle ``Spielstand anzeigen'' und ``Spielergebnis anzeigen''.\\


\subsection*{Nichtfunktionale Anforderungen}

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir nun für die Anforderungsspezifikation die nichtfunktionalen Anforderungen und jeweils einen dazu gehörigen Test.
        \vfill
    \end{tcolorbox}
    \caption{Prompt nichtfunktionale Anforderungen}
    \label{Prompt nichtfunktionale Anforderungen}
\end{prompt}

Dieser sehr einfach gehaltene Prompt wurde für die Erstellung der nichtfunktionalen Anforderungen verwendet. Es musste lediglich dazu erwähnt werden,
dass zu jeder Anforderung ein Test erstellt werden soll. Bei [ChatGPT und Le Chat] werden gute Anforderungen erstellt und die Tests passen auch 
sehr gut zu diesen. Hier werden die [beiden] Tools mit ``Sehr gut'' bewertet.

- Gemini:
    - passt


\section{Architekturdokument} \index{Architekturdokument} \label{CompArchitekturdokument}

Da auch das Architekturdokument ein umfangreiches Dokument ist, werden hier ebenfalls die Ausgaben der Technische Infrastruktur, des Komponentenmodells 
und der dynmaischen Beschreibung exemplarischer Anwendungsfälle im Komponentenmodell mithilfe eines Sequenzdiagrammes jeweils einzeln beschrieben und bewertet.

\subsection*{Technische Infrastruktur}

Da die Technische Infrastruktur auf die Systemübersicht aufbaut und alle drei Tools Schwierigkeiten hatten sich an dieses zu Erinnern, wurde die Textuelle 
Beschreibungen der jeweiligen Tools ihnen nochmal als Eingabe mitgegeben. Dazu beschreibt der Prompt, was die Technische Infrastruktur ist und was dort 
beschrieben ist. So kommt folgender Prompt zustande:

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        Erstell mir nun, basierend auf folgender Systemarchitektur, ein Diagramm und/oder eine Textuelle Beschreibung der Technischen Infrastruktur. 
        Diese Listet die Hardware- und Produktanforderungen auf: Hardware, Betriebssysteme, Produkte, Nachbarsysteme. Dabei sollen die einzelnen 
        Betriebssysteme mit Versionsnummer und die Verbindungen zwischen den Komponenten mit der Verbindungsart beschrieben werden: [Textuelle 
        Beschreibung der Systemübersicht des jeweiligen Tools]
        \vfill
    \end{tcolorbox}
    \caption{Prompt Technische Infrastruktur}
    \label{Prompt Technische Infrastruktur}
\end{prompt}

ChatGPT erstellt hier wieder eine Skizze in die Ausgabe mit. Diese ist auch ganz gut, lediglich die Datenbank ist etwas verrutscht. Negativ aufgefallen
ist die Beschreibung der Verbindung von der KI-Komponente. Hier wird beschrieben, dass diese in die Spiel-Logik auf der Server-Seite integriert ist und 
daher keine externe Verbindung erforderlich ist. In der Beschreibung der Systemübersicht wird die Spiel-Logig allerdings nur auf der Client-Seite erstellt.
Den Anwendsfällen entsprechend ist die Spiel-Logik auf der Server-Seite allerdings korrekt. Fragt man ChatGPT danach, wird ausgegeben, dass die Spiel-Logik 
beim Server hinzugefügt werden soll. Ansonsten wurde die Technische Infrastruktur von ChatGPT gut erstellt.\\

Gemini [[[[]]]]\\
    - Client-Anwendung ist Web-Anwendung
    - Datenbank auf Client-Seite?
    -> Erneute eingabe auch hier mit Systemübersicht
    - Auch hier wieder lokale Datenbank
    - Auch hier kein RMI -> Bei Hinweis wird nur Anpassungen, Vor- und Nachteile genannt
    - 

Auch Le Chat versucht eine Skizze in die Ausgabe mit einzufügen. Dies klappt hier allerdings nicht so richtig, da die Komponenten mit den Verbindungen nicht 
richtig verbunden werden. Während ChatGPT die Datenbank extern, als eigene Komponente definiert, ist bei Le Chat diese Teil des Servers. Außerdem werden bei den
Nachbarsystemen ein Externes Authentifizierungssystem sowie ein Zahlungssystem erstellt, was allerdings nicht Teil der Anforderungen war. Daher sind diese hier 
falsch. Jedoch passt die Zuweisung der Versionen für die Betriebssysteme sowie der Produkte ganz gut.\\


\subsection*{Komponentenmodell}

\begin{prompt}[H]
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
        1) Erstell mir nun für das Architekturdokument das Komponentenmodell. Das Komponentenmodell beschreibt die fachliche Struktur der Lösung auf 
        einer groben Ebene mittels eines UML-Komponenten-Diagramms.
        
        2) Beim Komponentenmodell handelt es sich nicht um die Technische Infrastruktur. Hier sollen die Komponenten und deren Schnittstellen erstellt 
        werden, die später für die Programmierung verwendet werden.
        \vfill
    \end{tcolorbox}
    \caption{Prompt Komponentenmodell}
    \label{Prompt Komponentenmodell}
\end{prompt}

Mithilfe des ersten Promptes wurde versucht das Komponentenmodell zu erstellen. Dies hat jedoch bei [ChatGPT und Le Chat] eher weniger funktioniert.
Beide Tools haben sich zu sehr an die Technische Infrastruktur gehalten und sind von diesem Format nicht weggekommen. Dadurch wurde bei [beiden] Tools
mit dem zweiten Prompt versucht diese davon etwas wegzubringen.\\

Bei ChatGPT hat dies dann auch schon ganz gut funktioniert, allerdings wird sich trotzdem noch stark an der Technischen Infrastruktur orientiert.
Außerdem sind keine Schnittstellen zwischen den Komponenten beschrieben worden. Es fällt auch auf, dass ``Game-Logic'', welche die Spielregeln implementiert
und lokale Spielzüge validiert, nur auf Client-Seite ist, was nicht den Anwendungsfällen entspricht, wo festgelegt wurde dass die Validierung der 
Spielzüge auf Server-Seite geschieht. Nach einer Eingabe, wo ChatGPT dies erklärt wird, wird ``Game-Logic'' auf Server-Seite geschoben. Außerdem werden 
die für die RMI nötigen Komponenten ``Client Communication'' und ``Server Communication'' hinzugefügt, welche vorher durch die ``Communication''- Komponente 
zwischen Client und Server falsch dargestellt wurde. Da nun allerdings auf der Server-Seite ``Game Logic'' und ``Game Manager'' vorhanden waren, 
urde ChatGPT gefragt ob man diese nicht zusammenfassen könnte. Dies wurde bejaht und die Komponenten wurde zu ``Game Manager/Logic'' 
zusammengefasst. Da der vom Kunden angeforderte Chat nirgends erwähnt wurde, wurde ChatGPT diesbezüglich nochmal gefragt ob dieser in einer Komponente 
enthalten sei oder eine eigene Komponente für diesen benötigt wird. Auch hier wurde dann die Komponente ``Chat Manager'' richtig erstellt und in das Diagramm 
eingefügt. Zusaätzlich könnte man noch eine ``Authentication''-Komponente in das Diagramm mit aufnehmen, welche sich um die Anmeldungen und 
Registrierungen und ähnliche Anwendungsfälle kümmert. Da der Chat ohne Probleme in das Diagramm mit aufgenommen wurde, wird das mit einer 
``Authentication''-Komponente ähnlich sein, weshalb dies nicht als extra Eingabe getätigt wurde. Zum Schluss wurde ChatGPT nochmal nach den Schnittstellen 
zwischen den Komponenten gefragt. Hier versucht ChatGPT allerdings die Funktionen, die dort benötigt werden, zu erstellen. Diese sind zum einen nicht 
vollständig und zum anderen an dieser Stelle falsch. Auch mit weiteren Eingaben lassen sich die Schnittstellen nicht richtig darstellen.\\

Gemini[[[]]]\\
    - PlantUML Code wird erstellt, aber Syntax Error
    - Misch-Masch aus Komponentenmodell und Technische Infrastruktur
    - Gewünschten Komponenten werden in der Beschreibung der erstellten Komponenten aufgelistet
    - 2. Prompt bringt nix
    -> Kann nicht davon weggebracht werden
    - Gleicher Prompt wie bei LeChat, nur ClientLogic in View umbenannt:
        - Hat gut funktioniert
        - Bei Nachfrage nach Schnittstellen wird wieder von den Komponenten von davor (Client, Server, DB) gesprochen


Wie zu beginn bereits erwähnt hatte Le Chat dasselbe Problem wie ChatGPT, dass dieser sich zu nah an der Technischen Infrastruktur orientiert hat.
Allerdings hat man Le Chat auch nach mehreren Eingaben nicht davon weggebracht. Die Beschreibung der Komponenten war eher bedürftig und es wurden 
keine Komponenten für die RMI Verbindung erstellt. Erst nach einer expliziten Eingabe, dass eine ``ClientCommunication''- und eine 
``ServerCommunication''-Komponente erforderlich ist, wurden diese erstellt. Das daraufhin erstellte Diagramm war allerdings eher wieder in der Form 
der Technischen Infrastruktur. Die Komponenten besaßen Interfaces, welche allerdings nicht richtig gepasst haben. Erst nach einer expliziten Eingabe, wie
das Komponentendiagramm auszusehen hat, wurde dieses Anständig erstellt. Allerdings haben auch hier die Schnittstellen gefehlt. Auf nachfrage diesbezüglich
wurden diese sogar einigermaßen ok erstellt. Allerdings werden auch hier schon die Methoden der Schnittstellen aufgelistet. Auch hier sind diese allerdings 
an der falschen Stelle erstellt worden und sind ebenfalls nicht vollständig. Dazu wurde beschrieben, dass die ``Data''-Komponente auf andere Schnittstellen
zugreif. Dies ist allerdings falsch, da die Datenbank ja keine Funktionen von alleine aufruft, sondern lediglich einen Return liefern soll. Nach einem Hinweis 
korrigiert Le Chat dies allerdings auch. Ein ähnliches Verhalten sieht man bei den anderen Komponenten auch, dass die Komponenten auf der Server-Seite in Richtung
Client-Seite Funktionen schicken können. Hier ist die Frage wie zum Beispiel eine Spielfeld aktualisierung umgesetzt werden soll. Wenn der Server die aktuellen 
Positionen der Spielfiguren von alleine an den Client schicken soll, müssen die Komponenten auf der Server-Seite richtung Client-Seite kommunizieren können.
Wenn man allerdings eine Funktion wie ``Spielfeld aktualisieren()'' auf der Client-Seite hinzufügt, könnte man die Daten über einen Return-Wert zurück schicken.
In diesem Fall müssten die Komponenten auf der Server-Seite nicht in Richtung Client-Seite kommunizieren können. Der letzte Auffällige Punkt ist, dass die 
Komponente ``ClientLogic'' die Schnittstelle ``ClientLogicInterface'' besitzt, auf welche von der Komponente ``Client-Anwendung'' zugegriffen wird. Nach dem 
Komponentendiagramm ist die ``ClientLogic''-Komponente allerdings die letzte auf der Client-Seite. Hier ist vermutlich die Anweisung, ``Als erstes gibt es 
eine ClientLogic-Komponente welche mit einer ClientCommunication-Komponente verbunden ist.'' ungeeignet gewesen, da hier interpretiert wird, dass die ``ClientLogic''
nur die Logik auf der Client-Seite umsetzt, nicht aber die Visuelle Darstellung. Daher hätte man die Komponente in der Eingabe besser ``View'' oder ähnlich nennen
sollen.\\


\subsection*{Sequenzdiagramm}

- Prompt: Kann einfach gehalten werden

- ChatGPT:
    Anmelden:
        - Ansich sehr gut direkt erstellt, lediglich ein paar Kleinigkeiten:
        - Benutzer interaktion mit angegeben, ist hier unnötigt. -> Wird gut geändert
        - ``GameManager/Logic''-Komponente validiert die Benutzerdaten mit den aus der DB erhaltenen Daten. -> Wird sowohl mit genauer Beschreibung, als uach mit ungenauer richtig 
        geändert.
        - Keine Schnittstellen namen, da diese auch nicht in Komponentenmodell erstellt werden konnten.
        - Zieht Benutzer mit Email und Passwort aus der Datenbank. Da keiner dieser Werte als einzigartig beschrieben wurde, können hier mehrere Benutzer zurückgegeben werden.
        [Mit Aktivitätsdiagramm vergleichen]
    Zug Machen:
        - Kein Würfeln enthalten und nicht passend zum Aktivitätsdiagramm
        - Sequenzdiagramm eher richtig als Aktivitätsdiagramm
        - Ebenfalls keine Schnittstellen
        - Frage wie Spiellbrett für die anderen Client aktualisiert wird. Über extra Anwendungsfall?
        - Betrachtet Figuren schlagen nicht -> Wird gemacht, überprüft aber nicht ob Figur selbe Farbe hat
        - Betrachtet überprüfung der Würfelzahl nicht

- Gemini:
    Anmelden:
        - Komponenten werden nicht übernommen -> Nach Hinweis, die Komponenten aus dem Modell zunutzen wird dies gemacht
        - Auch hier wieder Spieler eingaben mit beschrieben -> Auch nach Hinweis wird dies gemacht.
        - beschreibt nur was passiert, nennt keine Funktionen -> Wird nach Hinweis gemacht
        - Beteiligte Komponenten auch Spiellogik? Warum und wo?
        - ClientCommunication sendet an Spielserver
        - Authentication prüft Anmeldeinformationen in Data?? Daten müssen aus Data geholt werden und in Authentication geprüft werden.
        - Authentication sendet ergebnis an Spielserver?
        - ServerCommunication wurde überhaupt nicht verwendet
    
    Zug Machen:
        - Wird mehr oder weniger passend erstellt, besser als sonst
        - Beteiligte Komponenten auch Spielfigur und Würfel? Warum?? Dafür kein Authentication, schonmal besser als bei Anmelden
        - Auch hier erstmal wieder keine Funktionen erstellt sondern nur beschrieben was passiert -> Selbe eingabe wie bei Anmelden funktioniert
        wieder, allerdings wird auch hier wieder beschrieben, was der Spieler tut
        - Auch hier wird wieder von Spielserver gesprochen
        - Spielserver simuliert Würfelwurf in Würfel? Ähnelt eher einer Aktivität in einem Aktivitätsdiagramm
        - Wieso kann man Würfeln obwohl man nicht an der Reihe ist? Unnötigte Rechenzeit nutzung
        - Figur wird vom Server alleine bewegt? Oder die Parameter werden nicht übergeben? Beides doof
        - hört bei ClientCommunication auf? Denke mal die Ausgabe wurde einfach wieder abgebrochen 



- Le Chat:
    Anmelden:
        - Schafft es nicht PlantUML-Code fehlerfrei zu erstellen. Führt immer zu Syntax Error
        - Textuelle Beschreibung beschreibt Diagramm nur grob und nennt nicht die Funktionen. 
        - Arbeitet wieder mit ``Client-Anwendung''-Komponente
        - In Dialog und Anwendungsfall wurde Email-Adresse und Passwort als Eingabedaten verwendet. Kein Benutzernamen
        - Benutzername laut FDM nicht eindeutig, Daher können hier auch mehrere Benutzer gefunden werden
        - Muss benutzer zurück gegeben werden??
    Spielfigur setzen oder schlagen:
        - Auch hier wird wieder PlantUMl erstellt, aber auch wieder fehlerhaft
        - Passt nicht zu Anwendungsfall. Dort wurde Feld.x und Feld.y an Server übergeben, hier nur Zielfeld
        - spielID eigentlich nicht nötig übergeben zu werden, da Figuren einzigartige ID haben
        - Effizient das ganze Spiel aus der DB zu laden, einen Wert zu ändern und wieder zu speichern? -> Wird zu eigener Funktion geändert, wo
        nur Position der Figur geändert wird.
        - Lieber eine Funktion um Positionen der Figuren zu ändern, da dies sehr häufig gemacht werden muss.
        - Frage ob Punkt 10 nur an Client, der zug gemacht hat gesendet wird, oder an alle. -> Sagt das dies 
        an alle gemacht werden muss und dafür die ServerCommunication-Komponente eine Liste der Clients führen muss, 
        die am selben Spiel teilnehmen, und das Ereignis an alle Clients in dieser Liste senden.
        - Betrachtet Figuren schlagen nicht. -> Wird auf nachfrage korrigiert, erstellt aber keine Funktionen dafür sondern beschreibt nur
        - Außerdem wird nicht geprüft ob das Figuren bewegen mit dem Würfel übereinstimmt wie im Anwendungsfall beschrieben


\subsection*{Interfaces in Java}

- erste Ausgabe nicht passend zu Sequenzdiagrammen -> Bei Hinweis werden Sequenzdiagramme neu definiert. Allerdings falsch
- Schnittstellen passen nicht zu den Komponentendiagramm
-> Die Beschreibung der Sequenzdiagramme wurde nochmal als Eingabe mitgegeben
Anmelden:
- es wird extra Interface AuthenticationService erstellt, wo die Anmeldung abläuft. Macht Funktionen der GameManagerLogic aus dem Sequenzdiagramm sowie die Funktion der 
DatabaseAccess Komponente. GameManagerLogic leitet aufruf bei Java Implementierung nur weiter. AuthenticationService scheint daher Komponente zwischen GameManagerLogic 
und DatabaseAccess zu sein. In diesem Fall hat dann GameManagerLogic keine Aufgabe außer Funktionen weiterzuleiten. Könnte entfernt werden.
- UserInterface besitzt Mehtoden?? Sollte keine eigene Schnittstelle haben sondern nur auf ClientCommunication zugreifen
- Methodennamen passen nicht ganz zu denen aus dem Sequenzdiagramm
- Fraglich warum aufruf-Methoden auf Client-Seite void sind und dann extra Callback-Methoden erstellt werden, die True oder False zurückliefern. 
Einfacher die Aufruf-Methoden zu boolean zu machen

Zug Machen:
- GameService äquivalten zu AuthenticationService
- Auch Hier hier sind Aufruf-Methoden auf Client-Seite Void, warum nicht Rückgabewert MoveResponse, dann müssen keine Callback-Funktionen erstellt werden
- DatabaseAccess fehlt moveOccupyingFigureToStart() Funktion. Nur in GameService enthalten

-> Grundsätzlich ganz gut. GameService, AuthenticationService und DatabaseAccess nur etwas doppelt gemoppelt und nicht ganz ersichtlich welcher ablauf hier 
stattfindet. Rückgabewerte auf Client-Seite immer nur Void und dafür Callback-Funktionen. Warum nicht auch einfach Rückgabetyp boolean oder MoveReturn?


