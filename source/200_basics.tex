
\chapter{Grundlagen} \index{Grundlagen}

TODO!!!!!!!!!

\section{LLM Tools} \index{LLM Tools} \label{LLM Tools}

Unter LLM-Tools versteht man Sprachmodelle, die auf einem Large Language Model (LLM) basieren. Ein LLM ist ein 
Deep-Learning-Algorithmus, der mit sehr großen Datensätzen trainiert wird. Diese Modelle finden häufig Anwendung im 
Bereich des Natural Language Processing (NLP), wo sie verwendet werden, um Abfragen in natürlicher Sprache zu beantworten 
oder Ergebnisse zu liefern. LLMs können neue Inhalte verstehen, zusammenfassen, generieren und vorhersagen. Durch das Training 
sammeln LLMs Milliarden von Parametern, bei denen es sich um Variablen handelt, die im Modell angepasst werden, um neue 
Inhalte abzuleiten.\\
LLMs basieren auf einem Transformer-Modell, das Eingaben in Token umwandelt und dann gleichzeitig mathematische 
Gleichungen ausführt, um Beziehungen zwischen den Token zu ermitteln. Dadurch kann der Computer Muster erkennen, 
die auch ein Mensch wahrnehmen würde, wenn ihm die gleiche Frage gestellt wird. Zudem verwenden Transformer-Modelle 
Selbstaufmerksamkeitsmechanismen, die es dem Modell ermöglichen, schneller zu lernen als herkömmliche Modelle. 
Dadurch kann das Transformer-Modell verschiedene Teile der Sequenz oder den gesamten Kontext eines Satzes berücksichtigen, 
um Vorhersagen zu generieren.

Grundsätzlich bestehen LLMs aus vier neuronalen Netzwerkschichten: der wiederkehrenden Ebene, der Einbettungsebene, 
der Feedforward-Ebene und der Aufmerksamkeitsebene. Diese Schichten arbeiten zusammen, um den Eingabetext zu verarbeiten 
und Ausgabeinhalte zu generieren.\\
Die wiederkehrende Ebene dient dazu, die Wörter des Eingabetextes der Reihe nach zu interpretieren und die Beziehungen 
zwischen den Wörtern in einem Satz zu erfassen. Die Einbettungsebene erfasst die semantische und syntaktische Bedeutung 
der Eingabe, sodass das Modell den Kontext verstehen kann. Die Feedforward-Schicht besteht aus mehreren vollständig 
verbundenen Schichten, die die Eingabeeinbettungen transformieren. Dadurch ermöglichen diese Schichten dem Modell, 
Abstraktionen auf höherer Ebene zu verstehen und somit die Absicht des Benutzers mit der Texteingabe zu erfassen. Die 
Aufmerksamkeitsebene ermöglicht es dem Sprachmodell, sich auf einzelne Teile des Eingabetextes zu konzentrieren, die für 
die Aufgabe relevant sind, und dadurch die genausten Ausgaben zu generieren.

Damit ein großes Sprachmodell Texteingaben empfangen und eine Ausgabevorhersage generieren kann, muss es zunächst 
allgemein geschult und anschließend feinabgestimmt werden, um spezifische Aufgaben ausführen zu können. Für die 
Schulung werden riesige Datenmengen im Petabyte-Bereich benötigt. Das Training verläuft mehrstufig und beginnt in 
der Regel mit einem unbeaufsichtigten Lernansatz, bei dem das Modell mit unstrukturierten und unbeschrifteten Daten 
trainiert wird, da diese in größeren Mengen verfügbar sind. In dieser Phase leitet das Modell Beziehungen zwischen 
verschiedenen Wörtern und Konzepten ab.\\
Anschließend erfolgt die Schulung und Feinabstimmung durch eine Form des selbstüberwachten Lernens. Dabei wird eine 
Datenkennzeichnung durchgeführt, durch die das Modell verschiedene Konzepte besser und genauer identifizieren kann. 
Im nächsten Schritt durchläuft das LLM den transformatorischen neuronalen Netzwerkprozess im Rahmen des Deep Learning. 
Die Transformer-Modellarchitektur ermöglicht es dem LLM, mittels eines Selbstaufmerksamkeitsmechanismus Beziehungen 
und Verbindungen zwischen Wörtern und Konzepten zu erkennen, indem bestimmten Elementen (Token) Bewertungen zugewiesen 
werden, um die Beziehungen festzulegen.

Entscheidend über die Leistungsfähigkeit und die Qualität des Sprachmodells sind die Datensätze, welche zum trainieren
benutzt werden. Im folgenden wird auf die drei unterschiedliche LLM-Tools eingeganden, welche in dieser Arbeit näher 
untersucht werden\cite{GrundlagenLLM}. 

\subsection{ChatGPT} \index{ChatGPT} \label{ChatGPT}

ChatGPT wurde von dem Unternehmen OpenAI am 30. November 2022 veröffentlicht. Aufgrund der fortschrittlichen generativen 
KI-Fähigkeiten wurde der Chatbot schnell zu einer internationalen Sensation. Die Beta-Version der Plattform war 
ursprünglich kostenlos verfügbar, und OpenAI stellte den Nutzern weiterhin eine kostenlose Basisversion der Plattform zur 
Verfügung. Im Februar 2023 kündigte OpenAI ein kostenpflichtiges Abonnement an, das den Nutzern unbegrenzten Zugriff auf 
ChatGPT und eine breitere Palette von Funktionen und Diensten bietet.
Neben begeisterter Kritik löste ChatGPT jedoch auch schnell mehrere Kontroversen aus. Es wurden fehlerbehaftete 
Antworten ausgegeben, insbesondere wenn sie aufgefordert werden, Schlussfolgerungen zu ziehen, Nuancen zu untersuchen, 
Meinungen zu analysieren oder Vorhersagen zu treffen. Außerdem äußerten sich Pädagogen auf der ganzen Welt besorgt über 
den Platz von ChatGPT im Klassenzimmer und auch an Universitäten wurde der Einsatz von ChatGPT kritisch gesehen.
Doch auch mit den Kontroversen schien ChatGPT bereit zu sein, die Art und Weise, wie Internetnutzerinhalte erstellt werden,
zu revolutionieren. Webentwickler und Ersteller von Inhalten begannen schnell, ChatGPT als Recherche- und Schreibhilfe für 
Website-Texte zu nutzen.
Im März 2023 veröffentlichte OpenAI eine neue Version, bekannt als GPT-4. Ein großer Unterschied ist, dass GPT-4 
Eingaben sowohl in text- als auch in bildbasierten Formaten akzeptiert, was dem ChatBot ermöglicht, Daten aus 
Diagrammen, Grafiken und Screenshots zu interpretieren. Ebenfalls macht GPT-4 weitaus weniger Denkfehler und sachliche 
Fehler, die in der KI als "Halluzinationen" bezeichnet werden, als das GPT-3.5-Modell, das in der ersten ChatGPT-Version 
verwendet wurde. Am Ende des Jahres war es immer fortschrittlicher geworden und ChatGPT könnte beispielsweise Bilder 
analysieren, Sprachansagen abhören und seine eigene gesprochene Antwort anbieten. Im Mai 2024 kündigte OpenAI ein 
aktualisiertes Modell namens ChatGPT-4o an, das schnellere Ergebnisse und verbesserte Text- und Audiofunktionen versprach,
einschließlich eines neuen Konversations-KI-Systems namens "Sky"\cite{GrundlagenChatGPT}.

Wenn man ChatGPT fragt, ob es einen Infotext zu sich selbst erstellen kann erhält man folgende Antwort:

\begin{figure}[H] 
    \begin{tcolorbox}[colback=gray!20, colframe=gray!20, boxrule=0pt, sharp corners] 
    \textbf{Prompt: Erstell mir einen Infotext über dich für meine Bachelorarbeit}\\ 

    ChatGPT ist ein fortschrittlicher KI-gestützter Sprachassistent, der auf der GPT-4-Architektur von OpenAI basiert. 
    Entwickelt im Rahmen der Forschung und Entwicklung im Bereich Künstliche Intelligenz, ist ChatGPT in der Lage, 
    natürliche Sprache zu verstehen und darauf zu antworten. Dies macht ihn zu einem vielseitigen Werkzeug für eine 
    Vielzahl von Anwendungen, von der Beantwortung alltäglicher Fragen bis hin zur Unterstützung bei komplexeren 
    Aufgaben wie dem Schreiben von Texten, der Generierung von Ideen und der Bereitstellung von Informationen.\\
    
    Die GPT-4-Architektur, auf der ChatGPT basiert, verwendet tiefes maschinelles Lernen, um menschliche Sprache zu 
    verarbeiten und zu erzeugen. Durch die Analyse großer Mengen an Textdaten kann das Modell Muster und Zusammenhänge 
    erkennen, die es ihm ermöglichen, kontextuell relevante und kohärente Antworten zu geben. Diese Fähigkeiten machen 
    ChatGPT zu einem nützlichen Instrument in Bereichen wie Bildung, Forschung, Kundenservice und mehr.\\
    
    Ein weiterer bemerkenswerter Aspekt von ChatGPT ist seine Fähigkeit, sich an eine Vielzahl von Themen anzupassen 
    und Informationen auf klare und präzise Weise zu vermitteln. Dies wird durch kontinuierliches Training und 
    Verbesserung des Modells erreicht, wobei sowohl technische Fortschritte als auch Nutzerfeedback berücksichtigt 
    werden.\\
    
    Zusammengefasst ist ChatGPT ein leistungsstarker und vielseitiger KI-Assistent, der durch seine fortschrittliche 
    Technologie und seine breite Anwendbarkeit einen wertvollen Beitrag in vielen Bereichen leistet.\\
\vfill
    \end{tcolorbox}
\end{figure}

Wenn man 

\subsection{Google Gemini} \index{Google Gemini} \label{Google Gemini}

Google Gemini (ehemals Bard) wurde von DeepMind entwickelt, was ein Tochterunternehmen von Google ist.  
Das Erstveröffentlichungsdatum war der 6. Dezember 2023 und basiert auf der Meena-Architektur von Google AI,  
die 2020 veröffentlicht wurde.

\subsection{Le Chat} \index{Le Chat} \label{Le Chat}

Le Chat ist ein, von dem französischem KI-Startup Mistral AI veröffentlichter Chatbot. Mistral AI startete mit  
seinen frei verwendbaren Sprachmodellen, also auf der Grundlage von Open Source, erfolgreich durch. Nun(????)  
hat Mistral AI sein bislang größtes Modell 'Mistral Large' veröffentlicht. Diesmal allerdings nicht auf der  
Basis von Open Source, sondern ausschließlich über die eigene Webseite und der KI-Infrastruktur Microsoft  
Azure. Es lassen sich allerdings API-Keys für Programmierschnittstellen erstellen, um z.B. Mistral Large über  
seinen eigenen Server laufen zu lassen und so für andere User auf der eigenen Homepage verfügbar zu machen.  
Mit Mistral Large wurde auch Le Chat veröffentlicht, welcher aktuell(?????????) kostenfrei verwendet werden kann.
Le Chat bietet derzeit noch sehr wenige Funktionen an. Es stehen Lediglich Texteingabe und -ausgabe zur Verfügung.  
Die Datengrundlage reicht nur bis 2021, weshalb es auch hier, für die Jahre 2022 bis heute, zu der Problematik der  
Halluzination kommen kann.
Grundsätzlich kann man zwischen drei Sprachmodellen auswählen: Large, Next und Small. Large bietet überlegene Denkfähigkeit,  
Next ist ein Prototyp-Modell für erhöhte Kürze und Small arbeitet schnell und kosteneffektiv. \cite{GrundlagenLeChat}

\section{Software Engineering Prozess}
Test Verweis auf Buch \cite{Sommerville10} Das ist ein Text.
\subsection{einzelne Phasen} \index{einzelne Phasen} \label{einzelne Phasen}
